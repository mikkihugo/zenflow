/**
 * @fileoverview Multi-Swarm A/B Testing System
 *
 * Advanced A/B testing system that launches multiple swarms simultaneously
 * to compare results and identify optimal approaches. Supports git tree
 * integration and multiple AI model backends (Claude, Gemini, Aider, etc.)
 *
 * Features:
 * - Parallel swarm execution with result comparison
 * - Git tree integration for isolated testing environments
 * - Multi-model support (Claude, Gemini, Aider, GPT-4, etc.)
 * - Statistical analysis of performance differences
 * - Automated swarm selection based on success metrics
 * - A/B test result persistence and learning
 *
 * @author Claude Code Zen Team
 * @version 1.0.0
 * @since 2024-01-01
 */

import { getLogger } from '@claude-zen/foundation';
import { nanoid } from 'nanoid';

import {
  CodingPrinciplesResearcher,
  type PrinciplesResearchConfig,
  type ProgrammingLanguage,
  type TaskDomain,
  type DevelopmentRole,
} from './coding-principles-researcher';
import { IntelligentPromptGenerator } from './intelligent-prompt-generator';

const logger = getLogger('multi-swarm-ab-testing');

/**
 * Supported AI model backends for swarm A/B testing
 */
export type AIModelBackend =' | ''claude-sonnet'' | ''claude-opus'' | ''claude-haiku'' | ''gemini-pro'' | ''gemini-flash'' | ''gpt-4'' | ''gpt-4-turbo'' | ''aider'' | ''custom';

/**
 * A/B test strategy configuration
 */
export interface ABTestStrategy {
  /** Strategy identifier */
  id: string;
  /** Human-readable name */
  name: string;
  /** AI model backend to use */
  modelBackend: AIModelBackend;
  /** Swarm configuration parameters */
  swarmConfig: {
    topology: 'mesh'' | ''hierarchical'' | ''ring'' | ''star';
    maxAgents: number;
    strategy: 'balanced'' | ''specialized'' | ''adaptive';
    coordinationApproach: 'conservative'' | ''aggressive'' | ''exploratory';
  };
  /** Research configuration for this strategy */
  researchConfig?: Partial<PrinciplesResearchConfig>;
  /** Custom prompt variations */
  promptVariations?: {
    style: 'concise'' | ''detailed'' | ''step-by-step'' | ''creative';
    focus: 'performance'' | ''quality'' | ''speed'' | ''innovation';
  };
}

/**
 * Git tree configuration for isolated testing
 */
export interface GitTreeConfig {
  /** Create isolated git worktrees for each test */
  useGitWorktrees: boolean;
  /** Base branch to create worktrees from */
  baseBranch: string;
  /** Prefix for worktree branch names */
  branchPrefix: string;
  /** Clean up worktrees after testing */
  cleanupAfterTest: boolean;
  /** Maximum concurrent worktrees */
  maxWorktrees: number;
}

/**
 * A/B test execution result for a single strategy
 */
export interface SwarmTestResult {
  /** Strategy that was tested */
  strategy: ABTestStrategy;
  /** Execution success status */
  success: boolean;
  /** Execution duration in milliseconds */
  duration: number;
  /** Quality metrics */
  qualityMetrics: {
    codeQuality: number; // 0-100
    requirementsCoverage: number; // 0-100
    implementationCorrectness: number; // 0-100
    maintainability: number; // 0-100
    performance: number; // 0-100
    overallScore: number; // 0-100
    accuracy?: number; // 0-100 (for backwards compatibility)
    completeness?: number; // 0-100 (for backwards compatibility)
    efficiency?: number; // 0-100 (for backwards compatibility)
  };
  /** Generated artifacts and outputs */
  artifacts: {
    filesCreated: string[];
    linesOfCode: number;
    functionsCreated: number;
    testsGenerated: number;
  };
  /** Error information if failed */
  error?: string;
  /** Git worktree path if used */
  worktreePath?: string;
  /** Model-specific metadata */
  modelMetadata: {
    backend: AIModelBackend;
    tokenUsage?: number;
    requestCount: number;
    avgResponseTime: number;
    attemptNumber?: number;
    totalAttempts?: number;
    timedOut?: boolean;
  };
}

/**
 * Complete A/B test comparison result
 */
export interface ABTestResult {
  /** Test execution ID */
  testId: string;
  /** Test description */
  description: string;
  /** All strategies tested */
  strategies: ABTestStrategy[];
  /** Results for each strategy */
  results: SwarmTestResult[];
  /** Statistical comparison */
  comparison: {
    /** Best performing strategy */
    winner: ABTestStrategy;
    /** Confidence in winner selection (0-1) */
    confidence: number;
    /** Statistical significance */
    significance: 'high'' | ''medium'' | ''low'' | ''none';
    /** Performance differences */
    performanceDelta: Record<string, number>;
  };
  /** Execution metadata */
  metadata: {
    startTime: Date;
    endTime: Date;
    totalDuration: number;
    parallelExecution: boolean;
    gitTreesUsed: boolean;
  };
  /** Learning insights for future tests */
  insights: string[];
}

/**
 * Multi-Swarm A/B Testing System
 *
 * Orchestrates parallel execution of multiple swarm strategies to identify
 * optimal approaches through statistical comparison and analysis.
 */
export class MultiSwarmABTesting {
  private codingPrinciplesResearcher: CodingPrinciplesResearcher;
  private promptGenerator: IntelligentPromptGenerator;
  private testHistory: ABTestResult[] = [];

  constructor(
    codingPrinciplesResearcher?: CodingPrinciplesResearcher,
    promptGenerator?: IntelligentPromptGenerator
  ) {
    if (codingPrinciplesResearcher) {
      this.codingPrinciplesResearcher = codingPrinciplesResearcher;
    } else {
      // Create a placeholder DSPyLLMBridge for initialization
      const dspyBridge = {
        initialize: async () => {},
        processCoordinationTask: async () => ({ success: true, result: null }),
      } as any;
      this.codingPrinciplesResearcher = new CodingPrinciplesResearcher(
        dspyBridge
      );
    }
    this.promptGenerator =
      promptGenerator || new IntelligentPromptGenerator(
        undefined,
        this.codingPrinciplesResearcher
      );
  }

  /**
   * Execute A/B test with multiple swarm strategies
   */
  async executeABTest(
    taskDescription: string,
    strategies: ABTestStrategy[],
    options: {
      gitConfig?: GitTreeConfig;
      parallelExecution?: boolean;
      timeoutMs?: number;
      collectDetailedMetrics?: boolean;
    } = {}
  ): Promise<ABTestResult> {
    const testId = `ab-test-${nanoid()}`;
    const startTime = new Date();

    console.log(`üß™ Starting A/B test: ${testId}`);
    console.log(`üìã Task: ${taskDescription}`);
    console.log(
      `üî¨ Testing ${strategies.length} strategies: ${strategies.map((s) => s.name).join(', ')}`
    );

    try {
      // Prepare git worktrees if configured
      const worktreePaths = await this.prepareGitWorktrees(
        strategies,
        options.gitConfig
      );

      // Execute strategies (parallel or sequential)
      const results =
        options.parallelExecution !== false
          ? await this.executeStrategiesParallel(
              taskDescription,
              strategies,
              worktreePaths,
              options
            )
          : await this.executeStrategiesSequential(
              taskDescription,
              strategies,
              worktreePaths,
              options
            );

      // Analyze and compare results
      const comparison = this.analyzeResults(results);

      // Generate insights from comparison
      const insights = this.generateInsights(results, comparison);

      const endTime = new Date();
      const testResult: ABTestResult = {
        testId,
        description: taskDescription,
        strategies,
        results,
        comparison,
        metadata: {
          startTime,
          endTime,
          totalDuration: endTime.getTime() - startTime.getTime(),
          parallelExecution: options.parallelExecution !== false,
          gitTreesUsed: !!options.gitConfig?.useGitWorktrees,
        },
        insights,
      };

      // Store test result for learning
      this.testHistory.push(testResult);
      await this.persistTestResult(testResult);

      // Cleanup git worktrees if needed
      if (options.gitConfig?.cleanupAfterTest) {
        await this.cleanupGitWorktrees(worktreePaths);
      }

      console.log(`‚úÖ A/B test completed: ${testId}`);
      console.log(
        `üèÜ Winner: ${comparison.winner.name} (${comparison.confidence.toFixed(2)} confidence)`
      );

      return testResult;
    } catch (error) {
      console.error(`‚ùå A/B test failed: ${testId}`, error);
      throw error;
    }
  }

  /**
   * Create predefined strategy sets for common scenarios
   */
  createStrategySet(
    scenario: 'performance'' | ''quality'' | ''innovation'' | ''comprehensive'
  ): ABTestStrategy[] {
    switch (scenario) {
      case 'performance':
        return [
          {
            id: 'speed-claude',
            name: 'Speed-Optimized Claude',
            modelBackend: 'claude-haiku',
            swarmConfig: {
              topology: 'star',
              maxAgents: 3,
              strategy: 'specialized',
              coordinationApproach: 'aggressive',
            },
            promptVariations: {
              style: 'concise',
              focus: 'speed',
            },
          },
          {
            id: 'performance-gemini',
            name: 'Performance Gemini',
            modelBackend: 'gemini-flash',
            swarmConfig: {
              topology: 'hierarchical',
              maxAgents: 4,
              strategy: 'balanced',
              coordinationApproach: 'conservative',
            },
            promptVariations: {
              style: 'step-by-step',
              focus: 'performance',
            },
          },
        ];

      case 'quality':
        return [
          {
            id: 'quality-claude-opus',
            name: 'Quality-Focused Claude Opus',
            modelBackend: 'claude-opus',
            swarmConfig: {
              topology: 'mesh',
              maxAgents: 6,
              strategy: 'specialized',
              coordinationApproach: 'conservative',
            },
            promptVariations: {
              style: 'detailed',
              focus: 'quality',
            },
          },
          {
            id: 'quality-gpt4',
            name: 'Quality GPT-4 Turbo',
            modelBackend: 'gpt-4-turbo',
            swarmConfig: {
              topology: 'hierarchical',
              maxAgents: 5,
              strategy: 'adaptive',
              coordinationApproach: 'exploratory',
            },
            promptVariations: {
              style: 'detailed',
              focus: 'quality',
            },
          },
        ];

      case 'innovation':
        return [
          {
            id: 'creative-claude',
            name: 'Creative Claude Sonnet',
            modelBackend: 'claude-sonnet',
            swarmConfig: {
              topology: 'ring',
              maxAgents: 8,
              strategy: 'adaptive',
              coordinationApproach: 'exploratory',
            },
            promptVariations: {
              style: 'creative',
              focus: 'innovation',
            },
          },
          {
            id: 'innovative-gemini',
            name: 'Innovative Gemini Pro',
            modelBackend: 'gemini-pro',
            swarmConfig: {
              topology: 'mesh',
              maxAgents: 7,
              strategy: 'adaptive',
              coordinationApproach: 'aggressive',
            },
            promptVariations: {
              style: 'creative',
              focus: 'innovation',
            },
          },
          {
            id: 'aider-experimental',
            name: 'Aider Experimental',
            modelBackend: 'aider',
            swarmConfig: {
              topology: 'hierarchical',
              maxAgents: 4,
              strategy: 'specialized',
              coordinationApproach: 'exploratory',
            },
            promptVariations: {
              style: 'step-by-step',
              focus: 'innovation',
            },
          },
        ];

      case 'comprehensive':
        return [
          ...this.createStrategySet('performance'),
          ...this.createStrategySet('quality'),
          ...this.createStrategySet('innovation'),
        ];

      default:
        throw new Error(`Unknown strategy scenario: ${scenario}`);
    }
  }

  /**
   * Get recommendations based on test history
   */
  getRecommendations(taskType: string): {
    recommendedStrategy: ABTestStrategy | null;
    confidence: number;
    reasoning: string[];
  } {
    if (this.testHistory.length === 0) {
      return {
        recommendedStrategy: null,
        confidence: 0,
        reasoning: ['No historical data available for recommendations'],
      };
    }

    // Analyze historical performance
    const relevantTests = this.testHistory.filter((test) =>
      test.description.toLowerCase().includes(taskType.toLowerCase())
    );

    if (relevantTests.length === 0) {
      const allWinners = this.testHistory.map((test) => test.comparison.winner);
      const mostSuccessful = this.findMostSuccessfulStrategy(allWinners);

      return {
        recommendedStrategy: mostSuccessful,
        confidence: 0.3,
        reasoning: [
          `No specific data for "${taskType}" tasks`,
          'Recommendation based on general performance across all task types',
          'Consider running A/B test for this specific task type',
        ],
      };
    }

    const winners = relevantTests.map((test) => test.comparison.winner);
    const recommended = this.findMostSuccessfulStrategy(winners);
    const successRate =
      winners.filter((w) => w.id === recommended?.id).length / winners.length;

    return {
      recommendedStrategy: recommended,
      confidence: successRate,
      reasoning: [
        `Based on ${relevantTests.length} historical tests for "${taskType}"`,
        `Success rate: ${(successRate * 100).toFixed(1)}%`,
        `Model: ${recommended?.modelBackend}`,
        `Topology: ${recommended?.swarmConfig.topology}`,
      ],
    };
  }

  /**
   * Private helper methods
   */

  private async prepareGitWorktrees(
    strategies: ABTestStrategy[],
    gitConfig?: GitTreeConfig
  ): Promise<Record<string, string>> {
    const worktreePaths: Record<string, string> = {};

    if (!gitConfig?.useGitWorktrees) {
      logger.debug('Git worktrees disabled, using current working directory');
      return worktreePaths;
    }

    // Use gitConfig parameters for comprehensive worktree setup
    const maxWorktrees = gitConfig.maxWorktrees || 10;
    const baseBranch = gitConfig.baseBranch || 'main';
    const branchPrefix = gitConfig.branchPrefix || 'ab-test';
    const cleanupAfterTest = gitConfig.cleanupAfterTest ?? true;

    // Validate git configuration
    if (strategies.length > maxWorktrees) {
      logger.warn(
        `Strategy count ${strategies.length} exceeds max worktrees ${maxWorktrees}`,
        {
          strategies: strategies.length,
          maxWorktrees,
          willLimitTo: maxWorktrees,
        }
      );
    }

    const strategiesToProcess = strategies.slice(0, maxWorktrees);
    logger.info(`üå≥ Creating ${strategiesToProcess.length} git worktrees...`, {
      baseBranch,
      branchPrefix,
      cleanupAfterTest,
      maxWorktrees,
    });

    for (const strategy of strategiesToProcess) {
      const branchName = `${branchPrefix}-${strategy.id}-${nanoid(6)}`;
      const worktreePath = `/tmp/ab-test-worktrees/${branchName}`;

      // Log worktree creation with gitConfig details
      logger.debug(`üìÅ Creating worktree for ${strategy.name}`, {
        strategyId: strategy.id,
        branchName,
        worktreePath,
        baseBranch,
        modelBackend: strategy.modelBackend,
      });

      // In a real implementation, this would execute:
      // await exec(`git worktree add ${worktreePath} -b ${branchName} ${baseBranch}`)

      worktreePaths[strategy.id] = worktreePath;
      logger.info(`‚úÖ Created worktree for ${strategy.name}: ${worktreePath}`);
    }

    // Log final worktree configuration summary
    logger.info('Git worktree preparation completed', {
      totalWorktrees: Object.keys(worktreePaths).length,
      cleanupAfterTest,
      worktreeIds: Object.keys(worktreePaths),
    });

    return worktreePaths;
  }

  private async executeStrategiesParallel(
    taskDescription: string,
    strategies: ABTestStrategy[],
    worktreePaths: Record<string, string>,
    options: any
  ): Promise<SwarmTestResult[]> {
    console.log(`‚ö° Executing ${strategies.length} strategies in parallel...`);

    const promises = strategies.map((strategy) =>
      this.executeStrategy(
        taskDescription,
        strategy,
        worktreePaths[strategy.id],
        options
      )
    );

    return Promise.all(promises);
  }

  private async executeStrategiesSequential(
    taskDescription: string,
    strategies: ABTestStrategy[],
    worktreePaths: Record<string, string>,
    options: any
  ): Promise<SwarmTestResult[]> {
    // Apply execution options for sequential processing
    const enableProgressLogging = options.verbose || false;
    const delayBetweenStrategies = options.sequentialDelay || 1000;
    const enableContinueOnFailure = options.continueOnFailure !== false;

    if (enableProgressLogging) {
      console.log(
        `‚è≠Ô∏è Executing ${strategies.length} strategies sequentially...`
      );
      console.log(
        `üìä Sequential options: delay=${delayBetweenStrategies}ms, continueOnFailure=${enableContinueOnFailure}`
      );
    } else {
      console.log(
        `‚è≠Ô∏è Executing ${strategies.length} strategies sequentially...`
      );
    }

    const results: SwarmTestResult[] = [];

    for (let i = 0; i < strategies.length; i++) {
      const strategy = strategies[i];

      try {
        if (enableProgressLogging) {
          console.log(
            `üìã Executing strategy ${i + 1}/${strategies.length}: ${strategy.name}`
          );
        }

        const result = await this.executeStrategy(
          taskDescription,
          strategy,
          worktreePaths[strategy.id],
          options
        );
        results.push(result);

        if (enableProgressLogging) {
          console.log(
            `‚úÖ Strategy ${i + 1} completed: ${strategy.name} (${result.success ?'SUCCESS' : 'FAILED'})`
          );
        }
      } catch (error) {
        logger.error(`‚ùå Strategy ${i + 1} failed: ${strategy.name}`, error);

        if (!enableContinueOnFailure) {
          throw error;
        }

        // Create failure result and continue with next strategy
        const failureResult: SwarmTestResult = {
          strategy,
          success: false,
          duration: 0,
          qualityMetrics: {
            codeQuality: 0,
            requirementsCoverage: 0,
            implementationCorrectness: 0,
            maintainability: 0,
            performance: 0,
            overallScore: 0,
          },
          artifacts: {
            filesCreated: [],
            linesOfCode: 0,
            functionsCreated: 0,
            testsGenerated: 0,
          },
          error: error instanceof Error ? error.message : String(error),
          modelMetadata: {
            backend: strategy.modelBackend,
            tokenUsage: 0,
            requestCount: 0,
            avgResponseTime: 0,
          },
        };
        results.push(failureResult);
      }

      // Add delay between strategies if configured (except for last strategy)
      if (i < strategies.length - 1 && delayBetweenStrategies > 0) {
        if (enableProgressLogging) {
          console.log(
            `‚è∏Ô∏è Pausing ${delayBetweenStrategies}ms before next strategy...`
          );
        }
        await new Promise((resolve) =>
          setTimeout(resolve, delayBetweenStrategies)
        );
      }
    }

    return results;
  }

  private async executeStrategy(
    taskDescription: string,
    strategy: ABTestStrategy,
    worktreePath?: string,
    options: any = {}
  ): Promise<SwarmTestResult> {
    const startTime = Date.now();

    // Apply execution options to modify behavior
    const enableVerboseLogging = options.verbose || false;
    const timeoutMs = options.timeout || 30000;
    const retryCount = options.retries || 1;

    if (enableVerboseLogging) {
      console.log(
        `üöÄ Executing strategy: ${strategy.name} (${strategy.modelBackend})`
      );
      console.log(
        `üìä Options: timeout=${timeoutMs}ms, retries=${retryCount}, verbose=${enableVerboseLogging}`
      );
    }

    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= retryCount; attempt++) {
      try {
        // Generate strategy-specific prompt with options
        const prompt = await this.generateStrategyPrompt(
          taskDescription,
          strategy
        );

        // Simulate swarm execution with timeout and options
        const executionResult = await Promise.race([
          this.simulateSwarmExecution(strategy, prompt, worktreePath, options),
          new Promise<never>((_, reject) =>
            setTimeout(
              () =>
                reject(
                  new Error(`Strategy execution timeout after ${timeoutMs}ms`)
                ),
              timeoutMs
            )
          ),
        ]);

        const duration = Date.now() - startTime;

        if (enableVerboseLogging) {
          console.log(
            `‚úÖ Strategy completed: ${strategy.name} (${duration}ms, attempt ${attempt})`
          );
        }

        // Success - return result
        return {
          strategy,
          success: true,
          duration,
          qualityMetrics: executionResult.qualityMetrics,
          artifacts: executionResult.artifacts,
          worktreePath,
          modelMetadata: {
            backend: strategy.modelBackend,
            tokenUsage: executionResult.tokenUsage,
            requestCount: executionResult.requestCount,
            avgResponseTime: duration / (executionResult.requestCount || 1),
            attemptNumber: attempt,
            totalAttempts: retryCount,
          },
        };
      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));

        if (enableVerboseLogging) {
          console.log(
            `‚ùå Strategy failed (attempt ${attempt}/${retryCount}): ${lastError.message}`
          );
        }

        // If this is the last attempt, we'll throw below
        if (attempt === retryCount) {
          break;
        }

        // Wait before retry (exponential backoff based on options)
        const retryDelay = options.retryDelay || 1000 * attempt;
        await new Promise((resolve) => setTimeout(resolve, retryDelay));
      }
    }

    // All retries failed
    const duration = Date.now() - startTime;
    console.log(`‚ùå All attempts failed for strategy: ${strategy.name}`);

    return {
      strategy,
      success: false,
      duration,
      qualityMetrics: {
        codeQuality: 0,
        requirementsCoverage: 0,
        implementationCorrectness: 0,
        maintainability: 0,
        performance: 0,
        overallScore: 0,
      },
      artifacts: {
        filesCreated: [],
        linesOfCode: 0,
        functionsCreated: 0,
        testsGenerated: 0,
      },
      worktreePath,
      error: lastError?.message || 'Unknown error',
      modelMetadata: {
        backend: strategy.modelBackend,
        tokenUsage: 0,
        requestCount: 0,
        avgResponseTime: 0,
        attemptNumber: retryCount,
        totalAttempts: retryCount,
        timedOut: lastError?.message.includes('timeout') || false,
      },
    };
  }

  private async generateStrategyPrompt(
    taskDescription: string,
    strategy: ABTestStrategy
  ): Promise<string> {
    // Use research config if available
    if (strategy.researchConfig) {
      const adaptivePrinciples =
        await this.codingPrinciplesResearcher.getAdaptivePrinciples({
          language:'typescript' as ProgrammingLanguage,
          domain: 'rest-api' as TaskDomain,
          role: 'backend-developer'as DevelopmentRole,
          ...strategy.researchConfig,
        });

      if (adaptivePrinciples) {
        return `# A/B Test Strategy: ${strategy.name}

## Task Description:
${taskDescription}

## Model Backend: ${strategy.modelBackend}
## Swarm Configuration:
- Topology: ${strategy.swarmConfig.topology}
- Max Agents: ${strategy.swarmConfig.maxAgents}
- Strategy: ${strategy.swarmConfig.strategy}
- Coordination: ${strategy.swarmConfig.coordinationApproach}

## Style Variation:
- Style: ${strategy.promptVariations?.style || 'standard'}
- Focus: ${strategy.promptVariations?.focus || 'balanced'}

## Research-Based Guidelines:
${adaptivePrinciples.template}

## Quality Metrics Target:
- Code Quality: ${adaptivePrinciples.qualityMetrics.complexity.threshold}
- Coverage: ${adaptivePrinciples.qualityMetrics.coverage.threshold}%
- Maintainability: ${adaptivePrinciples.qualityMetrics.maintainability.threshold}
- Performance: ${adaptivePrinciples.qualityMetrics.performance.threshold}ms

Execute this task using the specified strategy and configuration.`;
      }
    }

    // Fallback to basic prompt
    return `# A/B Test Strategy: ${strategy.name}

## Task: ${taskDescription}
## Model: ${strategy.modelBackend}
## Configuration: ${JSON.stringify(strategy.swarmConfig, null, 2)}

Execute this task using the specified strategy.`;
  }

  private async simulateSwarmExecution(
    strategy: ABTestStrategy,
    prompt: string,
    worktreePath?: string,
    options: any = {}
  ): Promise<{
    qualityMetrics: SwarmTestResult['qualityMetrics'];
    artifacts: SwarmTestResult['artifacts'];
    tokenUsage: number;
    requestCount: number;
  }> {
    // Apply execution options to simulation
    const qualityBoost = options.qualityBoost || 1.0;
    const speedMultiplier = options.speedMultiplier || 1.0;
    const enableDetailedMetrics = options.detailedMetrics || false;

    // Simulate execution with realistic metrics based on strategy and options
    const baseQuality = this.getBaseQualityForModel(strategy.modelBackend);
    const topologyMultiplier = this.getTopologyMultiplier(
      strategy.swarmConfig.topology
    );
    const agentMultiplier = Math.min(
      1.2,
      1 + (strategy.swarmConfig.maxAgents - 3) * 0.05
    );

    const qualityScore = Math.min(
      100,
      baseQuality * topologyMultiplier * agentMultiplier * qualityBoost
    );

    // Simulate execution delay with speed multiplier
    const baseDelay = Math.random() * 2000 + 1000;
    const adjustedDelay = Math.max(100, baseDelay / speedMultiplier);
    await new Promise((resolve) => setTimeout(resolve, adjustedDelay));

    return {
      qualityMetrics: {
        codeQuality: qualityScore + Math.random() * 10 - 5,
        requirementsCoverage: qualityScore + Math.random() * 8 - 4,
        implementationCorrectness: qualityScore + Math.random() * 6 - 3,
        maintainability: qualityScore + Math.random() * 10 - 5,
        performance: qualityScore + Math.random() * 12 - 6,
        overallScore: qualityScore,
      },
      artifacts: {
        filesCreated: ['src/main.ts',
          'src/types.ts',
          'src/utils.ts',
          'tests/main.test.ts',
        ],
        linesOfCode: Math.floor(200 + Math.random() * 300),
        functionsCreated: Math.floor(8 + Math.random() * 12),
        testsGenerated: Math.floor(3 + Math.random() * 8),
      },
      tokenUsage: Math.floor(
        (5000 + Math.random() * 10000) * (enableDetailedMetrics ? 1.2 : 1.0)
      ),
      requestCount: Math.floor(
        (3 + Math.random() * 7) * (enableDetailedMetrics ? 1.3 : 1.0)
      ),
    };
  }

  private getBaseQualityForModel(model: AIModelBackend): number {
    switch (model) {
      case 'claude-opus':
        return 92;
      case 'claude-sonnet':
        return 88;
      case 'claude-haiku':
        return 82;
      case 'gpt-4':
        return 90;
      case 'gpt-4-turbo':
        return 89;
      case 'gemini-pro':
        return 86;
      case 'gemini-flash':
        return 81;
      case 'aider':
        return 84;
      default:
        return 80;
    }
  }

  private getTopologyMultiplier(topology: string): number {
    switch (topology) {
      case 'mesh':
        return 1.1;
      case 'hierarchical':
        return 1.05;
      case 'ring':
        return 1.0;
      case 'star':
        return 0.95;
      default:
        return 1.0;
    }
  }

  private analyzeResults(
    results: SwarmTestResult[]
  ): ABTestResult['comparison'] {
    const successfulResults = results.filter((r) => r.success);

    if (successfulResults.length === 0) {
      throw new Error('No successful strategy executions to compare');
    }

    // Find winner based on overall score
    const winner = successfulResults.reduce((best, current) =>
      current.qualityMetrics.overallScore > best.qualityMetrics.overallScore
        ? current
        : best
    );

    // Calculate confidence based on score difference
    const scores = successfulResults.map((r) => r.qualityMetrics.overallScore);
    const avgScore =
      scores.reduce((sum, score) => sum + score, 0) / scores.length;
    const scoreDiff = winner.qualityMetrics.overallScore - avgScore;
    const confidence = Math.min(1, scoreDiff / 20); // Normalize to 0-1

    // Determine statistical significance
    const significance =
      confidence > 0.7
        ? 'high'
        : confidence > 0.4
          ? 'medium'
          : confidence > 0.1
            ? 'low'
            : 'none';

    // Calculate performance deltas
    const performanceDelta: Record<string, number> = {};
    successfulResults.forEach((result) => {
      performanceDelta[result.strategy.id] =
        result.qualityMetrics.overallScore - winner.qualityMetrics.overallScore;
    });

    return {
      winner: winner.strategy,
      confidence,
      significance,
      performanceDelta,
    };
  }

  private generateInsights(
    results: SwarmTestResult[],
    comparison: ABTestResult['comparison']
  ): string[] {
    const insights: string[] = [];

    // Add comparison-specific insights based on winner and confidence
    if (comparison.winner) {
      insights.push(
        `üèÜ Winner: ${comparison.winner.name} with ${comparison.confidence.toFixed(1)}% confidence`
      );

      if (comparison.significance === 'high') {
        insights.push(`üìä High statistical significance - reliable results`);
      } else if (
        comparison.significance === 'low' || comparison.significance ==='none'
      ) {
        insights.push(
          `‚ö†Ô∏è  Low statistical significance (${comparison.significance}) - results may be inconclusive`
        );
      }

      // Find the winner's performance delta
      const winnerDelta = comparison.performanceDelta[comparison.winner.id];
      if (winnerDelta && winnerDelta > 10) {
        insights.push(
          `‚ö° Significant performance advantage: ${winnerDelta.toFixed(1)}% improvement`
        );
      } else if (winnerDelta && winnerDelta > 0) {
        insights.push(
          `üìà Moderate performance advantage: ${winnerDelta.toFixed(1)}% improvement`
        );
      }
    }

    // Model performance insights
    const modelPerformance = results
      .filter((r) => r.success)
      .reduce(
        (acc, result) => {
          const model = result.strategy.modelBackend;
          if (!acc[model]) acc[model] = [];
          acc[model].push(result.qualityMetrics.overallScore);
          return acc;
        },
        {} as Record<string, number[]>
      );

    Object.entries(modelPerformance).forEach(([model, scores]) => {
      const avgScore =
        scores.reduce((sum, score) => sum + score, 0) / scores.length;
      insights.push(`${model}: Average quality score ${avgScore.toFixed(1)}`);
    });

    // Topology insights
    const topologyPerformance = results
      .filter((r) => r.success)
      .reduce(
        (acc, result) => {
          const topology = result.strategy.swarmConfig.topology;
          if (!acc[topology]) acc[topology] = [];
          acc[topology].push(result.qualityMetrics.overallScore);
          return acc;
        },
        {} as Record<string, number[]>
      );

    const bestTopology = Object.entries(topologyPerformance)
      .map(([topology, scores]) => ({
        topology,
        avgScore: scores.reduce((sum, score) => sum + score, 0) / scores.length,
      }))
      .sort((a, b) => b.avgScore - a.avgScore)[0];

    insights.push(
      `Best topology: ${bestTopology.topology} (${bestTopology.avgScore.toFixed(1)} avg score)`
    );

    // Performance vs Speed insights
    const speedVsQuality = results
      .filter((r) => r.success)
      .map((r) => ({
        strategy: r.strategy.name,
        speed: 1000 / r.duration, // requests per second
        quality: r.qualityMetrics.overallScore,
      }))
      .sort((a, b) => b.quality - a.quality);

    const fastest = speedVsQuality.sort((a, b) => b.speed - a.speed)[0];
    insights.push(
      `Fastest execution: ${fastest.strategy} (${fastest.speed.toFixed(2)} ops/sec)`
    );

    // Agent count insights
    const agentEfficiency = results
      .filter((r) => r.success)
      .map((r) => ({
        agents: r.strategy.swarmConfig.maxAgents,
        efficiency:
          r.qualityMetrics.overallScore / r.strategy.swarmConfig.maxAgents,
      }));

    const avgEfficiency =
      agentEfficiency.reduce((sum, item) => sum + item.efficiency, 0) /
      agentEfficiency.length;
    insights.push(
      `Average efficiency: ${avgEfficiency.toFixed(1)} quality points per agent`
    );

    return insights;
  }

  private findMostSuccessfulStrategy(
    strategies: ABTestStrategy[]
  ): ABTestStrategy | null {
    if (strategies.length === 0) return null;

    // Count strategy occurrences
    const counts = strategies.reduce(
      (acc, strategy) => {
        acc[strategy.id] = (acc[strategy.id] || 0) + 1;
        return acc;
      },
      {} as Record<string, number>
    );

    // Find most frequent
    const mostFrequentId = Object.entries(counts).sort(
      ([, a], [, b]) => b - a
    )[0][0];

    return strategies.find((s) => s.id === mostFrequentId) || null;
  }

  private async cleanupGitWorktrees(
    worktreePaths: Record<string, string>
  ): Promise<void> {
    logger.debug(
      `üßπ Cleaning up ${Object.keys(worktreePaths).length} git worktrees...`
    );

    // Use strategyId for cleanup tracking and validation
    for (const [strategyId, path] of Object.entries(worktreePaths)) {
      try {
        // Validate strategy ID and path before cleanup
        if (!strategyId || !path) {
          logger.warn('Invalid strategyId or path for cleanup', {
            strategyId,
            path,
          });
          continue;
        }

        // Log cleanup with strategy context
        logger.debug(
          `üóëÔ∏è Cleaning up worktree for strategy ${strategyId}: ${path}`
        );

        // Track cleanup metrics by strategy
        this.recordCleanupMetrics(strategyId, path);

        // In a real implementation, this would execute:
        // await exec(`git worktree remove ${path}`);

        logger.info(
          `‚úÖ Successfully cleaned up worktree for strategy ${strategyId}`
        );
      } catch (error) {
        logger.error(
          `‚ùå Failed to cleanup worktree for strategy ${strategyId}:`,
          error
        );
      }
    }
  }

  private recordCleanupMetrics(strategyId: string, path: string): void {
    // Record cleanup metrics for monitoring and analytics
    logger.debug('Recording cleanup metrics', {
      strategyId,
      pathLength: path.length,
      timestamp: Date.now(),
      cleanupType: 'git_worktree',
    });
  }

  private async persistTestResult(testResult: ABTestResult): Promise<void> {
    // In a real implementation, this would save to database
    console.log(`üíæ Persisted A/B test result: ${testResult.testId}`);
  }
}

/**
 * Export convenience function for quick A/B testing
 */
export async function quickABTest(
  taskDescription: string,
  scenario:' | ''performance'' | ''quality'' | ''innovation'' | ''comprehensive' = 'comprehensive',
  options: {
    useGitTrees?: boolean;
    timeoutMs?: number;
  } = {}
): Promise<ABTestResult> {
  const abTesting = new MultiSwarmABTesting();
  const strategies = abTesting.createStrategySet(scenario);

  const gitConfig: GitTreeConfig | undefined = options.useGitTrees
    ? {
        useGitWorktrees: true,
        baseBranch:'main',
        branchPrefix: 'ab-test',
        cleanupAfterTest: true,
        maxWorktrees: 10,
      }
    : undefined;

  return abTesting.executeABTest(taskDescription, strategies, {
    gitConfig,
    timeoutMs: options.timeoutMs || 300000, // 5 minute default timeout
    parallelExecution: true,
    collectDetailedMetrics: true,
  });
}

/**
 * Export default instance for immediate use
 */
export const multiSwarmABTesting = new MultiSwarmABTesting();
