# ðŸ›¡ï¸ Adaptive Memory System - Quick Start Guide

## âœ¨ **Zero OOM Guarantee**

Claude Code Zen now features an **ultra-conservative adaptive memory system** that **never causes out-of-memory errors** while automatically optimizing performance based on your system capabilities.

## ðŸš€ **How It Works**

### **1. Conservative Startup (Always)**
```bash
# Regardless of your system memory (8GB, 32GB, or even 2TB):
# System ALWAYS starts with minimal resource usage

8GB System:   Uses ~896MB initially (11% of capacity)
16GB System:  Uses ~896MB initially (5.5% of capacity) 
32GB System:  Uses ~896MB initially (2.7% of capacity)
128GB System: Uses ~896MB initially (0.7% of capacity)
```

### **2. Real-Time Performance Monitoring**
The system continuously tracks:
- Memory utilization patterns
- Memory spike detection  
- CPU usage trends
- Error rates
- Throughput metrics
- Memory volatility (stability)

### **3. Ultra-Safe Scaling Rules**

#### **Scale DOWN (Immediate)**
```typescript
// ANY of these conditions triggers immediate scale-down:
if (memoryUsage > 60% || 
    memorySpike > 65% || 
    errorRate > 0.1% ||
    memoryVolatility > 15%) {
  
  scaleDown(40-60%); // Aggressive reduction
}
```

#### **Scale UP (Requires Perfection)**
```typescript
// ALL conditions must be perfect for 30+ cycles:
if (memoryUsage < 25% && 
    memorySpike < 30% && 
    cpuUsage < 35% &&
    errorRate === 0 &&
    throughput > 25 &&
    memoryVolatility < 3% &&
    perfectHistoryFor30Cycles) {
  
  scaleUp(1%); // Tiny increase only
}
```

## ðŸ“Š **Example Scaling Behavior**

### **32GB System Timeline**
```
Minute 0:  Portfolio=4, Program=8, Swarm=16    (~896MB)
Minute 5:  Performance perfect, no scaling yet (collecting data)
Minute 15: Still perfect, maybe add 1 swarm stream  (~904MB)
Minute 30: Continued perfection, add 1 program stream (~936MB)
Hour 1:    Steady growth to Portfolio=6, Program=12, Swarm=24 (~1.3GB)

// If ANY memory pressure occurs:
Second 1:  Immediate scale down to Portfolio=3, Program=5, Swarm=12 (~568MB)
```

### **8GB System Timeline**
```
Minute 0:  Portfolio=2, Program=4, Swarm=8     (~448MB)
Minute 15: Perfect performance, add 1 swarm   (~456MB)
Minute 30: Add another swarm stream           (~464MB)
Hour 1:    Steady at Portfolio=3, Program=6, Swarm=12 (~672MB)

// Conservative growth appropriate for smaller system
```

## ðŸŽ¯ **Key Benefits**

### **âœ… Guaranteed Stability**
- **Never crashes** from memory exhaustion
- **Graceful degradation** under load
- **Self-healing** recovery from pressure
- **Predictable performance** characteristics

### **âš¡ Intelligent Adaptation**
- **Learns your system** over time
- **Adapts to workload** patterns
- **Optimizes automatically** without intervention
- **Scales conservatively** to prevent issues

### **ðŸ”§ Zero Configuration**
- **Auto-detects system** memory and capabilities
- **Works on any system** from 8GB to 2TB+
- **Requires no tuning** - works optimally out of the box
- **Safe defaults** for any environment

## ðŸš€ **Getting Started**

### **1. Initialize with Adaptive Memory**
```typescript
import { initializeCore } from './src/core/init.ts';
import { createRepoConfig } from './src/config/default-repo-config.ts';

// Auto-detects system and configures safely
await initializeCore();

// Creates ultra-conservative repo configuration
const repoConfig = createRepoConfig('/path/to/repo');
```

### **2. Monitor Adaptive Behavior**
```typescript
import { createAdaptiveOptimizer } from './src/config/memory-optimization.ts';

const optimizer = createAdaptiveOptimizer();

// Record performance metrics
optimizer.recordPerformance({
  memoryUtilization: 0.45,
  cpuUtilization: 0.30,
  throughput: 20,
  errorRate: 0
});

// Get performance summary
console.log(optimizer.getPerformanceSummary());
```

### **3. System Information**
```typescript
import { getSystemInfo, logSystemInfo } from './src/config/system-info.ts';

// Log detailed system analysis
logSystemInfo();

// Get programmatic system info
const info = getSystemInfo();
console.log(`Detected ${info.totalMemoryGB}GB system`);
console.log(`Recommended max streams: ${info.recommendedConfig.maxSwarmStreams}`);
```

## ðŸ” **Monitoring and Debugging**

### **Performance Summary**
```bash
ðŸŽ¯ Adaptive Performance Summary:
   Memory: 23.5% (decreasing)
   CPU: 28.1% (stable)  
   Throughput: 31.2/sec (increasing)
   Active Streams: 28
   Auto-scaling: âœ… ENABLED
   System optimized well - consider scaling up capacity
```

### **Memory Allocation Breakdown**
```bash
ðŸ–¥ï¸ System Information:
   Total Memory: 32GB (32768MB)
   Available Memory: 16GB (conservative estimate)
   Platform: linux
   CPU Cores: 12

ðŸŽ¯ Recommended Stream Limits (Ultra-Conservative):
   Portfolio: 8 streams max
   Program: 16 streams max  
   Swarm: 32 streams max
   Conservative Mode: NO
```

## âš™ï¸ **Advanced Configuration**

### **Custom Safety Margins**
```typescript
const customConfig = {
  portfolioStreamMB: 64,        // Reduce memory per stream
  maxMemoryUtilization: 0.4,    // Never exceed 40% memory
  scaleUpThreshold: 0.20,       // Only scale up if <20% memory
  optimizationInterval: 45000   // Check every 45 seconds
};

const optimizer = createMemoryOptimizer(customConfig);
```

### **Manual Control**
```typescript
// Disable auto-scaling for manual control
optimizer.setAutoScale(false);

// Manual capacity adjustments
const canAllocate = optimizer.canAllocateStream('swarm');
if (canAllocate) {
  optimizer.allocateStream('swarm', 'stream-123');
}
```

## ðŸ† **Why This Approach?**

### **Traditional Problems**
- Systems scale aggressively and crash
- Memory spikes cause unexpected OOM errors
- No adaptation to actual system conditions
- Manual tuning required for different machines

### **Our Solution**
- âœ… **Never crashes** - ultra-conservative by design
- âœ… **Handles spikes** - monitors volatility continuously
- âœ… **Self-adapting** - optimizes based on real performance
- âœ… **Works everywhere** - from 8GB laptops to 2TB servers

## ðŸŽ¯ **Perfect For**

- **Development environments** (8-16GB laptops)
- **Production servers** (32GB+ with high reliability needs)
- **Cloud instances** (variable memory allocations)
- **CI/CD systems** (shared resources with memory constraints)
- **Any system** where stability is more important than maximum throughput

---

**Result**: Rock-solid stability with intelligent performance adaptation that grows with your system capabilities! ðŸ›¡ï¸âœ¨