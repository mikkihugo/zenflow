[model]
name = "OptimizedTCN-PatternDetector"
version = "1.0.0"
framework = "ruv-swarm-ml"
model_type = "temporal_convolutional_network"
created_date = "2025-06-30"
last_updated = "2025-06-30"

[architecture]
input_dim = 128
sequence_length = 512
output_dim = 32
num_layers = 7
kernel_size = 3
dilation_rates = [1, 2, 4, 8, 16, 32, 64]
dropout_rate = 0.1
activation = "relu"
use_residual = true
use_batch_norm = true

[pattern_detection]
# Design Pattern Recognition
design_patterns = [
    "factory_pattern",
    "singleton",
    "observer", 
    "strategy",
    "command",
    "decorator",
    "adapter",
    "facade",
    "template_method",
    "builder",
    "prototype",
    "bridge",
    "composite",
    "flyweight",
    "proxy",
    "chain_of_responsibility"
]

# Anti-Pattern Detection
anti_patterns = [
    "god_object",
    "spaghetti_code",
    "copy_paste",
    "dead_code", 
    "long_method",
    "feature_envy",
    "data_clumps",
    "shotgun_surgery"
]

# Refactoring Opportunities
refactoring_opportunities = [
    "extract_method",
    "extract_class",
    "move_method",
    "rename_variable",
    "replace_magic_number",
    "simplify_conditional",
    "remove_duplication",
    "optimize_loop"
]

[training]
batch_size = 32
learning_rate = 0.001
max_epochs = 100
patience = 10
validation_split = 0.2
optimizer = "adamw"
weight_decay = 1e-4
gradient_clip_norm = 1.0

[training.scheduler]
type = "cosine_annealing"
t_max = 100
eta_min = 1e-6

[inference]
confidence_threshold = 0.75
nms_threshold = 0.5
batch_size = 64
use_temporal_smoothing = true
smoothing_window = 5

[preprocessing]
tokenizer = "subword_bpe"
vocab_size = 8192
max_sequence_length = 512
padding = "post"
truncation = "post"

[preprocessing.features]
syntax_features = true
semantic_features = true
structural_features = true
context_features = true
temporal_features = true

[swarm_integration]
# Swarm coordination features
enable_agent_interaction_analysis = true
enable_task_dependency_tracking = true
enable_communication_pattern_detection = true
enable_collaboration_metrics = true

[swarm_integration.coordination]
max_agents = 10
coordination_mode = "hierarchical"
communication_protocol = "message_passing"
task_scheduling = "priority_based"

[performance]
target_inference_time_ms = 15.0
max_memory_usage_mb = 8.0
min_accuracy = 0.85
min_f1_score = 0.82

[monitoring]
enable_metrics_collection = true
log_predictions = true
track_confidence_scores = true
enable_drift_detection = true

[monitoring.alerts]
low_confidence_threshold = 0.6
high_error_rate_threshold = 0.1
memory_usage_threshold = 0.9

[data]
training_data_path = "data/training/"
validation_data_path = "data/validation/"
test_data_path = "data/test/"
cache_processed_data = true
data_format = "json"

[data.augmentation]
enable_augmentation = true
noise_factor = 0.01
rotation_range = 5
sequence_shuffle_probability = 0.1

[deployment]
model_format = "onnx"
quantization = "int8"
batch_optimization = true
memory_mapping = true

[deployment.hardware]
target_device = "cpu"
enable_simd = true
enable_threading = true
max_threads = 4

[logging]
level = "info"
format = "json"
enable_file_logging = true
log_file = "logs/tcn_pattern_detector.log"
max_log_size_mb = 100
backup_count = 5