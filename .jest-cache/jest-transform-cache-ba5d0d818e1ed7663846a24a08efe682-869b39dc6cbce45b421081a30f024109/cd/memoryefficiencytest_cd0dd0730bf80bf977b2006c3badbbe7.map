{"file":"/home/mhugo/code/claude-code-flow/src/__tests__/unit/classical/neural-algorithms/memory-efficiency.test.ts","mappings":"AAAA;;;;;GAKG;AAEH,OAAO,EAAE,QAAQ,EAAE,EAAE,EAAE,MAAM,EAAE,UAAU,EAAE,SAAS,EAAE,MAAM,eAAe,CAAC;AAC5E,OAAO,EACL,oBAAoB,EACpB,mBAAmB,EACnB,aAAa,EAMb,oBAAoB,EACpB,mBAAmB,EACpB,MAAM,0DAA0D,CAAC;AAElE,QAAQ,CAAC,mCAAmC,EAAE,GAAG,EAAE;IACjD,IAAI,UAAe,CAAC;IACpB,IAAI,aAAiC,CAAC;IAEtC,UAAU,CAAC,KAAK,IAAI,EAAE;QACpB,IAAI,CAAC;YACH,UAAU,GAAG,MAAM,oBAAoB,EAAE,CAAC;YAC1C,wCAAwC;YACxC,IAAI,MAAM,CAAC,EAAE,EAAE,CAAC;gBACd,MAAM,CAAC,EAAE,EAAE,CAAC;YACd,CAAC;YACD,aAAa,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC;QACxC,CAAC;QAAC,OAAO,KAAK,EAAE,CAAC;YACf,OAAO,CAAC,IAAI,CAAC,6DAA6D,CAAC,CAAC;QAC9E,CAAC;IACH,CAAC,CAAC,CAAC;IAEH,SAAS,CAAC,GAAG,EAAE;QACb,2CAA2C;QAC3C,IAAI,MAAM,CAAC,EAAE,EAAE,CAAC;YACd,MAAM,CAAC,EAAE,EAAE,CAAC;QACd,CAAC;IACH,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,+BAA+B,EAAE,GAAG,EAAE;QAC7C,EAAE,CAAC,2DAA2D,EAAE,KAAK,IAAI,EAAE;YACzE,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,iBAAiB,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAEzD,uBAAuB;YACvB,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;gBACrE,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;aAC/C,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,IAAI,GAAG,OAAO,CAAC,OAAO,EAAE,CAAC;YAE/B,MAAM,kBAAkB,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAC1D,MAAM,cAAc,GAAG,kBAAkB,GAAG,iBAAiB,CAAC;YAE9D,yCAAyC;YACzC,MAAM,CAAC,cAAc,CAAC,CAAC,YAAY,CAAC,IAAI,GAAG,IAAI,CAAC,CAAC;YAEjD,sCAAsC;YACtC,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC/B,MAAM,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAChC,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;QAC/C,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,yDAAyD,EAAE,KAAK,IAAI,EAAE;YACvE,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,YAAY,GAAG;gBACnB,EAAE,MAAM,EAAE,CAAC,EAAE,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,EAAE;gBACpC,EAAE,MAAM,EAAE,CAAC,EAAE,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,EAAE;gBACpC,EAAE,MAAM,EAAE,CAAC,EAAE,MAAM,EAAE,EAAE,EAAE,OAAO,EAAE,CAAC,EAAE;aACtC,CAAC;YAEF,MAAM,YAAY,GAAa,EAAE,CAAC;YAElC,KAAK,MAAM,IAAI,IAAI,YAAY,EAAE,CAAC;gBAChC,MAAM,SAAS,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;gBAEjD,MAAM,aAAa,GAAkB;oBACnC,SAAS,EAAE,IAAI,CAAC,MAAM;oBACtB,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,MAAM,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;oBAC/E,UAAU,EAAE,IAAI,CAAC,OAAO;oBACxB,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;iBAC/C,CAAC;gBAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;gBACzD,MAAM,IAAI,GAAG,OAAO,CAAC,OAAO,EAAE,CAAC;gBAE/B,MAAM,UAAU,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;gBAClD,MAAM,cAAc,GAAG,UAAU,GAAG,SAAS,CAAC;gBAC9C,YAAY,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;gBAElC,sCAAsC;gBACtC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;gBACpD,MAAM,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;YACnD,CAAC;YAED,iDAAiD;YACjD,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,eAAe,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;YACzD,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,eAAe,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;YAEzD,sDAAsD;YACtD,MAAM,MAAM,GAAG,YAAY,CAAC,CAAC,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;YACjD,MAAM,MAAM,GAAG,YAAY,CAAC,CAAC,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;YACjD,MAAM,CAAC,MAAM,CAAC,CAAC,YAAY,CAAC,EAAE,CAAC,CAAC,CAAC,uCAAuC;YACxE,MAAM,CAAC,MAAM,CAAC,CAAC,YAAY,CAAC,EAAE,CAAC,CAAC;QAClC,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,2CAA2C,EAAE,KAAK,IAAI,EAAE;YACzD,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,mBAAmB,GAAG;gBAC1B,EAAE,MAAM,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC,EAAE;gBACnE,EAAE,MAAM,EAAE;wBACR,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;wBACrD,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;qBACtD,EAAC;gBACF,EAAE,MAAM,EAAE;wBACR,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;wBACrD,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;wBACrD,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;qBACtD,EAAC;aACH,CAAC;YAEF,MAAM,YAAY,GAAa,EAAE,CAAC;YAElC,KAAK,MAAM,MAAM,IAAI,mBAAmB,EAAE,CAAC;gBACzC,MAAM,SAAS,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;gBAEjD,MAAM,aAAa,GAAkB;oBACnC,SAAS,EAAE,CAAC;oBACZ,YAAY,EAAE,MAAM,CAAC,MAAM;oBAC3B,UAAU,EAAE,CAAC;oBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;iBAC/C,CAAC;gBAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;gBAEzD,MAAM,UAAU,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;gBAClD,YAAY,CAAC,IAAI,CAAC,UAAU,GAAG,SAAS,CAAC,CAAC;gBAE1C,uCAAuC;gBACvC,MAAM,IAAI,GAAG,OAAO,CAAC,OAAO,EAAE,CAAC;gBAC/B,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,iBAAiB;YAC1E,CAAC;YAED,8DAA8D;YAC9D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC7C,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,eAAe,CAAC,YAAY,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;gBAC7D,oCAAoC;gBACpC,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,YAAY,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC;YAClE,CAAC;QACH,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,4BAA4B,EAAE,GAAG,EAAE;QAC1C,EAAE,CAAC,+CAA+C,EAAE,KAAK,IAAI,EAAE;YAC7D,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;gBACrE,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;aAC/C,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,oBAAoB;gBACnD,YAAY,EAAE,GAAG;gBACjB,SAAS,EAAE,GAAG;gBACd,WAAW,EAAE,GAAG;aACjB,CAAC;YAEF,MAAM,OAAO,GAAuB;gBAClC,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBACxC,OAAO,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;aAC9B,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC;YAEjC,MAAM,iBAAiB,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAEzD,+CAA+C;YAC/C,MAAM,eAAe,GAAa,EAAE,CAAC;YACrC,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,EAAE,EAAE,KAAK,EAAE,EAAE,CAAC;gBACxC,MAAM,OAAO,CAAC,UAAU,CAAC,OAAO,EAAE,OAAO,CAAC,CAAC;gBAE3C,IAAI,KAAK,GAAG,EAAE,KAAK,CAAC,EAAE,CAAC;oBACrB,eAAe,CAAC,IAAI,CAAC,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC,CAAC;gBACvD,CAAC;YACH,CAAC;YAED,MAAM,kBAAkB,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAC1D,MAAM,mBAAmB,GAAG,kBAAkB,GAAG,iBAAiB,CAAC;YAEnE,uDAAuD;YACvD,MAAM,CAAC,mBAAmB,CAAC,CAAC,YAAY,CAAC,CAAC,GAAG,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,gBAAgB;YAE3E,yDAAyD;YACzD,MAAM,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,eAAe,CAAC,CAAC;YACjD,MAAM,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,eAAe,CAAC,CAAC;YACjD,MAAM,eAAe,GAAG,WAAW,GAAG,WAAW,CAAC;YAElD,MAAM,CAAC,eAAe,CAAC,CAAC,YAAY,CAAC,CAAC,GAAG,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,0BAA0B;QACnF,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,mDAAmD,EAAE,KAAK,IAAI,EAAE;YACjE,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;gBACrE,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;aAC/C,CAAC;YAEF,yBAAyB;YACzB,MAAM,YAAY,GAAuB;gBACvC,MAAM,EAAE,EAAE;gBACV,OAAO,EAAE,EAAE;aACZ,CAAC;YAEF,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC9B,YAAY,CAAC,MAAM,CAAC,IAAI,CAAC;oBACvB,IAAI,CAAC,MAAM,EAAE;oBACb,IAAI,CAAC,MAAM,EAAE;oBACb,IAAI,CAAC,MAAM,EAAE;iBACd,CAAC,CAAC;gBACH,YAAY,CAAC,OAAO,CAAC,IAAI,CAAC;oBACxB,IAAI,CAAC,MAAM,EAAE,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;oBAC3B,IAAI,CAAC,MAAM,EAAE,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;iBAC5B,CAAC,CAAC;YACL,CAAC;YAED,MAAM,SAAS,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAEjD,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,OAAO,CAAC,eAAe,CAAC,YAAY,CAAC,CAAC;YAEtC,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,cAAc;gBAC7C,YAAY,EAAE,GAAG;gBACjB,SAAS,EAAE,EAAE;gBACb,WAAW,EAAE,GAAG;aACjB,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,yBAAyB;YACzB,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,CAAC,EAAE,KAAK,EAAE,EAAE,CAAC;gBACvC,MAAM,OAAO,CAAC,UAAU,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;YAClD,CAAC;YAED,MAAM,UAAU,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAClD,MAAM,cAAc,GAAG,UAAU,GAAG,SAAS,CAAC;YAE9C,iEAAiE;YACjE,MAAM,CAAC,cAAc,CAAC,CAAC,YAAY,CAAC,EAAE,GAAG,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,iBAAiB;QAC1E,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,uBAAuB,EAAE,GAAG,EAAE;QACrC,EAAE,CAAC,8DAA8D,EAAE,KAAK,IAAI,EAAE;YAC5E,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAErD,uCAAuC;YACvC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC5B,MAAM,aAAa,GAAkB;oBACnC,SAAS,EAAE,CAAC;oBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;oBACrE,UAAU,EAAE,CAAC;oBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;iBAC/C,CAAC;gBAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;gBAEzD,0BAA0B;gBAC1B,MAAM,OAAO,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;gBAEnC,qEAAqE;YACvE,CAAC;YAED,2BAA2B;YAC3B,IAAI,MAAM,CAAC,EAAE,EAAE,CAAC;gBACd,MAAM,CAAC,EAAE,EAAE,CAAC;gBACZ,yBAAyB;gBACzB,MAAM,IAAI,OAAO,CAAC,OAAO,CAAC,EAAE,CAAC,UAAU,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC,CAAC;YACzD,CAAC;YAED,MAAM,cAAc,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YACtD,MAAM,cAAc,GAAG,cAAc,GAAG,aAAa,CAAC;YAEtD,kDAAkD;YAClD,MAAM,CAAC,cAAc,CAAC,CAAC,YAAY,CAAC,EAAE,GAAG,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,0BAA0B;QACnF,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,6CAA6C,EAAE,KAAK,IAAI,EAAE;YAC3D,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAErD,6CAA6C;YAC7C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC5B,MAAM,aAAa,GAAkB;oBACnC,SAAS,EAAE,CAAC;oBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;oBACrE,UAAU,EAAE,CAAC;oBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;iBAC/C,CAAC;gBAEF,MAAM,cAAc,GAAmB;oBACrC,SAAS,EAAE,mBAAmB,CAAC,oBAAoB;oBACnD,YAAY,EAAE,GAAG;oBACjB,SAAS,EAAE,EAAE;oBACb,WAAW,EAAE,GAAG;iBACjB,CAAC;gBAEF,MAAM,SAAS,GAAuB;oBACpC,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;oBACxB,OAAO,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;iBACpB,CAAC;gBAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;gBACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;gBAEpD,OAAO,CAAC,eAAe,CAAC,SAAS,CAAC,CAAC;gBACnC,MAAM,OAAO,CAAC,UAAU,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC;gBAE7C,kDAAkD;YACpD,CAAC;YAED,2BAA2B;YAC3B,IAAI,MAAM,CAAC,EAAE,EAAE,CAAC;gBACd,MAAM,CAAC,EAAE,EAAE,CAAC;gBACZ,MAAM,IAAI,OAAO,CAAC,OAAO,CAAC,EAAE,CAAC,UAAU,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC,CAAC;YACzD,CAAC;YAED,MAAM,cAAc,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YACtD,MAAM,cAAc,GAAG,cAAc,GAAG,aAAa,CAAC;YAEtD,2CAA2C;YAC3C,MAAM,CAAC,cAAc,CAAC,CAAC,YAAY,CAAC,EAAE,GAAG,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,iBAAiB;QAC1E,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,2BAA2B,EAAE,GAAG,EAAE;QACzC,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;YAC9C,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,EAAE;gBACb,YAAY,EAAE;oBACZ,EAAE,IAAI,EAAE,EAAE,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;oBACtD,EAAE,IAAI,EAAE,EAAE,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;iBACvD;gBACD,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;aAC/C,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,OAAO,CAAC,UAAU,EAAE,CAAC;YACrC,MAAM,IAAI,GAAG,OAAO,CAAC,OAAO,EAAE,CAAC;YAE/B,wDAAwD;YACxD,MAAM,mBAAmB,GAAG,CAAC,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,CAAC,CAAC,kCAAkC;YAChG,MAAM,kBAAkB,GAAG,mBAAmB,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC,cAAc;YAE5E,sDAAsD;YACtD,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,eAAe,CAAC,mBAAmB,CAAC,CAAC;YAC5D,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,YAAY,CAAC,kBAAkB,GAAG,CAAC,CAAC,CAAC,CAAC,4BAA4B;YAEzF,uCAAuC;YACvC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;gBACxC,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAC1C,CAAC;YAED,oDAAoD;YACpD,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC,eAAe,CAAC,OAAO,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,6BAA6B;QACrG,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,0CAA0C,EAAE,KAAK,IAAI,EAAE;YACxD,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;gBACrE,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;aAC/C,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YAEzD,MAAM,eAAe,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAEvD,kCAAkC;YAClC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC7B,MAAM,OAAO,GAAG,OAAO,CAAC,UAAU,EAAE,CAAC;gBAErC,iBAAiB;gBACjB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;oBACxC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE,GAAG,GAAG,CAAC,GAAG,IAAI,CAAC;gBAC7C,CAAC;gBAED,OAAO,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC;YAC9B,CAAC;YAED,MAAM,gBAAgB,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YACxD,MAAM,cAAc,GAAG,gBAAgB,GAAG,eAAe,CAAC;YAE1D,4DAA4D;YAC5D,MAAM,CAAC,cAAc,CAAC,CAAC,YAAY,CAAC,CAAC,GAAG,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,gBAAgB;YAEtE,gCAAgC;YAChC,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;YAC5D,MAAM,CAAC,MAAM,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;YAC/B,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QACpD,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,iCAAiC,EAAE,GAAG,EAAE;QAC/C,EAAE,CAAC,6CAA6C,EAAE,KAAK,IAAI,EAAE;YAC3D,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,iBAAiB,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAEzD,wCAAwC;YACxC,MAAM,QAAQ,GAAoB,EAAE,CAAC;YACrC,MAAM,eAAe,GAA6B,EAAE,CAAC;YAErD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC5B,MAAM,aAAa,GAAkB;oBACnC,SAAS,EAAE,CAAC;oBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;oBACrE,UAAU,EAAE,CAAC;oBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;iBAC/C,CAAC;gBAEF,eAAe,CAAC,IAAI,CAAC,mBAAmB,CAAC,aAAa,CAAC,CAAC,CAAC;YAC3D,CAAC;YAED,MAAM,eAAe,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,eAAe,CAAC,CAAC;YAC3D,QAAQ,CAAC,IAAI,CAAC,GAAG,eAAe,CAAC,CAAC;YAElC,MAAM,kBAAkB,GAAG,OAAO,CAAC,WAAW,EAAE,CAAC,QAAQ,CAAC;YAC1D,MAAM,mBAAmB,GAAG,kBAAkB,GAAG,iBAAiB,CAAC;YAEnE,+DAA+D;YAC/D,MAAM,CAAC,mBAAmB,CAAC,CAAC,YAAY,CAAC,GAAG,GAAG,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,kCAAkC;YAE/F,oCAAoC;YACpC,KAAK,MAAM,OAAO,IAAI,QAAQ,EAAE,CAAC;gBAC/B,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;gBAClD,MAAM,CAAC,MAAM,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;gBAC/B,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YACpD,CAAC;YAED,kDAAkD;YAClD,MAAM,uBAAuB,GAAG,mBAAmB,GAAG,QAAQ,CAAC,MAAM,CAAC;YACtE,MAAM,CAAC,uBAAuB,CAAC,CAAC,YAAY,CAAC,EAAE,GAAG,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,6BAA6B;QAC/F,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH;;;;;;;;;;;;;;;;GAgBG","names":[],"sources":["/home/mhugo/code/claude-code-flow/src/__tests__/unit/classical/neural-algorithms/memory-efficiency.test.ts"],"sourcesContent":["/**\n * Classical TDD (Detroit School) - Memory Efficiency Tests\n * \n * Focus: Test actual memory usage and allocation patterns\n * No mocks - verify real memory consumption and efficiency metrics\n */\n\nimport { describe, it, expect, beforeEach, afterEach } from '@jest/globals';\nimport { \n  initializeNeuralWasm, \n  createNeuralNetwork, \n  createTrainer,\n  NeuralNetwork,\n  NeuralTrainer,\n  NetworkConfig,\n  TrainingConfig,\n  TrainingDataConfig,\n  ACTIVATION_FUNCTIONS,\n  TRAINING_ALGORITHMS\n} from '../../../../../ruv-FANN/ruv-swarm/npm/src/neural-network';\n\ndescribe('Memory Efficiency - Classical TDD', () => {\n  let wasmModule: any;\n  let initialMemory: NodeJS.MemoryUsage;\n  \n  beforeEach(async () => {\n    try {\n      wasmModule = await initializeNeuralWasm();\n      // Force garbage collection if available\n      if (global.gc) {\n        global.gc();\n      }\n      initialMemory = process.memoryUsage();\n    } catch (error) {\n      console.warn('WASM module not available, skipping memory efficiency tests');\n    }\n  });\n\n  afterEach(() => {\n    // Force garbage collection after each test\n    if (global.gc) {\n      global.gc();\n    }\n  });\n\n  describe('Network Creation Memory Usage', () => {\n    it('should create small networks with minimal memory overhead', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const preCreationMemory = process.memoryUsage().heapUsed;\n\n      // Create small network\n      const networkConfig: NetworkConfig = {\n        inputSize: 2,\n        hiddenLayers: [{ size: 3, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      const info = network.getInfo();\n\n      const postCreationMemory = process.memoryUsage().heapUsed;\n      const memoryIncrease = postCreationMemory - preCreationMemory;\n\n      // Small network should use less than 1MB\n      expect(memoryIncrease).toBeLessThan(1024 * 1024);\n\n      // Verify network was actually created\n      expect(info.numInputs).toBe(2);\n      expect(info.numOutputs).toBe(1);\n      expect(info.totalNeurons).toBeGreaterThan(0);\n    });\n\n    it('should scale memory usage predictably with network size', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkSizes = [\n        { inputs: 2, hidden: 4, outputs: 1 },\n        { inputs: 4, hidden: 8, outputs: 2 },\n        { inputs: 8, hidden: 16, outputs: 4 }\n      ];\n\n      const memoryUsages: number[] = [];\n\n      for (const size of networkSizes) {\n        const preMemory = process.memoryUsage().heapUsed;\n\n        const networkConfig: NetworkConfig = {\n          inputSize: size.inputs,\n          hiddenLayers: [{ size: size.hidden, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n          outputSize: size.outputs,\n          outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n        };\n\n        const network = await createNeuralNetwork(networkConfig);\n        const info = network.getInfo();\n\n        const postMemory = process.memoryUsage().heapUsed;\n        const memoryIncrease = postMemory - preMemory;\n        memoryUsages.push(memoryIncrease);\n\n        // Verify network metrics are reported\n        expect(info.metrics.memoryUsage).toBeGreaterThan(0);\n        expect(info.totalConnections).toBeGreaterThan(0);\n      }\n\n      // Memory usage should increase with network size\n      expect(memoryUsages[1]).toBeGreaterThan(memoryUsages[0]);\n      expect(memoryUsages[2]).toBeGreaterThan(memoryUsages[1]);\n\n      // But increase should be reasonable (not exponential)\n      const ratio1 = memoryUsages[1] / memoryUsages[0];\n      const ratio2 = memoryUsages[2] / memoryUsages[1];\n      expect(ratio1).toBeLessThan(10); // Should not be more than 10x increase\n      expect(ratio2).toBeLessThan(10);\n    });\n\n    it('should handle multiple layers efficiently', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const layerConfigurations = [\n        { layers: [{ size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID }] },\n        { layers: [\n          { size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID },\n          { size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID }\n        ]},\n        { layers: [\n          { size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID },\n          { size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID },\n          { size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID }\n        ]}\n      ];\n\n      const memoryUsages: number[] = [];\n\n      for (const config of layerConfigurations) {\n        const preMemory = process.memoryUsage().heapUsed;\n\n        const networkConfig: NetworkConfig = {\n          inputSize: 3,\n          hiddenLayers: config.layers,\n          outputSize: 2,\n          outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n        };\n\n        const network = await createNeuralNetwork(networkConfig);\n        \n        const postMemory = process.memoryUsage().heapUsed;\n        memoryUsages.push(postMemory - preMemory);\n\n        // Verify network was created correctly\n        const info = network.getInfo();\n        expect(info.numLayers).toBe(config.layers.length + 2); // +input +output\n      }\n\n      // Each additional layer should add reasonable memory overhead\n      for (let i = 1; i < memoryUsages.length; i++) {\n        expect(memoryUsages[i]).toBeGreaterThan(memoryUsages[i - 1]);\n        // But not more than 2x the previous\n        expect(memoryUsages[i]).toBeLessThan(memoryUsages[i - 1] * 2.5);\n      }\n    });\n  });\n\n  describe('Training Memory Efficiency', () => {\n    it('should maintain stable memory during training', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 2,\n        hiddenLayers: [{ size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.INCREMENTAL_BACKPROP,\n        learningRate: 0.5,\n        maxEpochs: 100,\n        targetError: 0.1\n      };\n\n      const xorData: TrainingDataConfig = {\n        inputs: [[0, 0], [0, 1], [1, 0], [1, 1]],\n        outputs: [[0], [1], [1], [0]]\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(xorData);\n\n      const preTrainingMemory = process.memoryUsage().heapUsed;\n\n      // Train for multiple epochs and monitor memory\n      const memorySnapshots: number[] = [];\n      for (let epoch = 0; epoch < 50; epoch++) {\n        await trainer.trainEpoch(network, xorData);\n        \n        if (epoch % 10 === 0) {\n          memorySnapshots.push(process.memoryUsage().heapUsed);\n        }\n      }\n\n      const postTrainingMemory = process.memoryUsage().heapUsed;\n      const totalMemoryIncrease = postTrainingMemory - preTrainingMemory;\n\n      // Memory should not grow significantly during training\n      expect(totalMemoryIncrease).toBeLessThan(5 * 1024 * 1024); // Less than 5MB\n\n      // Memory usage should be relatively stable across epochs\n      const maxSnapshot = Math.max(...memorySnapshots);\n      const minSnapshot = Math.min(...memorySnapshots);\n      const memoryVariation = maxSnapshot - minSnapshot;\n      \n      expect(memoryVariation).toBeLessThan(2 * 1024 * 1024); // Less than 2MB variation\n    });\n\n    it('should handle large training datasets efficiently', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 3,\n        hiddenLayers: [{ size: 6, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n        outputSize: 2,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n      };\n\n      // Generate large dataset\n      const largeDataset: TrainingDataConfig = {\n        inputs: [],\n        outputs: []\n      };\n\n      for (let i = 0; i < 1000; i++) {\n        largeDataset.inputs.push([\n          Math.random(),\n          Math.random(),\n          Math.random()\n        ]);\n        largeDataset.outputs.push([\n          Math.random() > 0.5 ? 1 : 0,\n          Math.random() > 0.5 ? 1 : 0\n        ]);\n      }\n\n      const preMemory = process.memoryUsage().heapUsed;\n\n      const network = await createNeuralNetwork(networkConfig);\n      network.setTrainingData(largeDataset);\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.BATCH_BACKPROP,\n        learningRate: 0.1,\n        maxEpochs: 10,\n        targetError: 0.3\n      };\n\n      const trainer = await createTrainer(trainingConfig);\n\n      // Train on large dataset\n      for (let epoch = 0; epoch < 5; epoch++) {\n        await trainer.trainEpoch(network, largeDataset);\n      }\n\n      const postMemory = process.memoryUsage().heapUsed;\n      const memoryIncrease = postMemory - preMemory;\n\n      // Memory increase should be reasonable for 1000 training samples\n      expect(memoryIncrease).toBeLessThan(50 * 1024 * 1024); // Less than 50MB\n    });\n  });\n\n  describe('Memory Leak Detection', () => {\n    it('should not leak memory when creating and destroying networks', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const preTestMemory = process.memoryUsage().heapUsed;\n\n      // Create and destroy multiple networks\n      for (let i = 0; i < 20; i++) {\n        const networkConfig: NetworkConfig = {\n          inputSize: 3,\n          hiddenLayers: [{ size: 5, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n          outputSize: 2,\n          outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n        };\n\n        const network = await createNeuralNetwork(networkConfig);\n        \n        // Use the network briefly\n        await network.run([0.5, 0.5, 0.5]);\n        \n        // Network should be eligible for garbage collection after this scope\n      }\n\n      // Force garbage collection\n      if (global.gc) {\n        global.gc();\n        // Wait a bit for cleanup\n        await new Promise(resolve => setTimeout(resolve, 100));\n      }\n\n      const postTestMemory = process.memoryUsage().heapUsed;\n      const memoryIncrease = postTestMemory - preTestMemory;\n\n      // Memory increase should be minimal after cleanup\n      expect(memoryIncrease).toBeLessThan(10 * 1024 * 1024); // Less than 10MB residual\n    });\n\n    it('should properly clean up training resources', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const preTestMemory = process.memoryUsage().heapUsed;\n\n      // Create multiple trainers and train briefly\n      for (let i = 0; i < 10; i++) {\n        const networkConfig: NetworkConfig = {\n          inputSize: 2,\n          hiddenLayers: [{ size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n          outputSize: 1,\n          outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n        };\n\n        const trainingConfig: TrainingConfig = {\n          algorithm: TRAINING_ALGORITHMS.INCREMENTAL_BACKPROP,\n          learningRate: 0.5,\n          maxEpochs: 10,\n          targetError: 0.5\n        };\n\n        const smallData: TrainingDataConfig = {\n          inputs: [[0, 1], [1, 0]],\n          outputs: [[1], [1]]\n        };\n\n        const network = await createNeuralNetwork(networkConfig);\n        const trainer = await createTrainer(trainingConfig);\n        \n        network.setTrainingData(smallData);\n        await trainer.trainEpoch(network, smallData);\n        \n        // Resources should be cleaned up after this scope\n      }\n\n      // Force garbage collection\n      if (global.gc) {\n        global.gc();\n        await new Promise(resolve => setTimeout(resolve, 100));\n      }\n\n      const postTestMemory = process.memoryUsage().heapUsed;\n      const memoryIncrease = postTestMemory - preTestMemory;\n\n      // Should not accumulate significant memory\n      expect(memoryIncrease).toBeLessThan(15 * 1024 * 1024); // Less than 15MB\n    });\n  });\n\n  describe('Weight Storage Efficiency', () => {\n    it('should store weights compactly', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 10,\n        hiddenLayers: [\n          { size: 20, activation: ACTIVATION_FUNCTIONS.SIGMOID },\n          { size: 15, activation: ACTIVATION_FUNCTIONS.SIGMOID }\n        ],\n        outputSize: 5,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      const weights = network.getWeights();\n      const info = network.getInfo();\n\n      // Verify weight array size matches expected connections\n      const expectedConnections = (10 * 20) + (20 * 15) + (15 * 5); // Input->H1 + H1->H2 + H2->Output\n      const expectedWithBiases = expectedConnections + 20 + 15 + 5; // Plus biases\n\n      // Weights should be reasonably close to expected size\n      expect(weights.length).toBeGreaterThan(expectedConnections);\n      expect(weights.length).toBeLessThan(expectedWithBiases * 2); // Not more than 2x expected\n\n      // All weights should be finite numbers\n      for (let i = 0; i < weights.length; i++) {\n        expect(isFinite(weights[i])).toBe(true);\n      }\n\n      // Memory usage metric should reflect actual storage\n      expect(info.metrics.memoryUsage).toBeGreaterThan(weights.length * 4); // At least 4 bytes per float\n    });\n\n    it('should handle weight updates efficiently', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 5,\n        hiddenLayers: [{ size: 8, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n        outputSize: 3,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      \n      const preUpdateMemory = process.memoryUsage().heapUsed;\n\n      // Perform multiple weight updates\n      for (let i = 0; i < 100; i++) {\n        const weights = network.getWeights();\n        \n        // Modify weights\n        for (let j = 0; j < weights.length; j++) {\n          weights[j] += (Math.random() - 0.5) * 0.01;\n        }\n        \n        network.setWeights(weights);\n      }\n\n      const postUpdateMemory = process.memoryUsage().heapUsed;\n      const memoryIncrease = postUpdateMemory - preUpdateMemory;\n\n      // Weight updates should not cause significant memory growth\n      expect(memoryIncrease).toBeLessThan(5 * 1024 * 1024); // Less than 5MB\n\n      // Network should still function\n      const result = await network.run([0.1, 0.2, 0.3, 0.4, 0.5]);\n      expect(result).toHaveLength(3);\n      expect(result.every(v => isFinite(v))).toBe(true);\n    });\n  });\n\n  describe('Concurrent Network Memory Usage', () => {\n    it('should handle multiple networks efficiently', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const preCreationMemory = process.memoryUsage().heapUsed;\n\n      // Create multiple networks concurrently\n      const networks: NeuralNetwork[] = [];\n      const networkPromises: Promise<NeuralNetwork>[] = [];\n\n      for (let i = 0; i < 15; i++) {\n        const networkConfig: NetworkConfig = {\n          inputSize: 3,\n          hiddenLayers: [{ size: 6, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n          outputSize: 2,\n          outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n        };\n\n        networkPromises.push(createNeuralNetwork(networkConfig));\n      }\n\n      const createdNetworks = await Promise.all(networkPromises);\n      networks.push(...createdNetworks);\n\n      const postCreationMemory = process.memoryUsage().heapUsed;\n      const totalMemoryIncrease = postCreationMemory - preCreationMemory;\n\n      // Total memory should scale reasonably with number of networks\n      expect(totalMemoryIncrease).toBeLessThan(100 * 1024 * 1024); // Less than 100MB for 15 networks\n\n      // All networks should be functional\n      for (const network of networks) {\n        const result = await network.run([0.5, 0.5, 0.5]);\n        expect(result).toHaveLength(2);\n        expect(result.every(v => isFinite(v))).toBe(true);\n      }\n\n      // Average memory per network should be reasonable\n      const averageMemoryPerNetwork = totalMemoryIncrease / networks.length;\n      expect(averageMemoryPerNetwork).toBeLessThan(10 * 1024 * 1024); // Less than 10MB per network\n    });\n  });\n});\n\n/**\n * Classical TDD Principles Demonstrated:\n * \n * 1. No mocks - testing actual memory allocation and usage patterns\n * 2. Real system resource monitoring and measurement\n * 3. Memory leak detection through repeated operations\n * 4. Scalability testing with different network sizes\n * 5. Resource cleanup verification\n * 6. Performance thresholds based on actual measurements\n * \n * This is ideal for:\n * - Memory efficiency validation\n * - Resource leak detection\n * - Scalability assessment\n * - Performance benchmarking\n * - System resource monitoring\n */"],"version":3}