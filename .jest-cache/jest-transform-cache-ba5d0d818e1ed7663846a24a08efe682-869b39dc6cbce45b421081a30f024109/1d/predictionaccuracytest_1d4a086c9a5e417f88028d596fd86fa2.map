{"file":"/home/mhugo/code/claude-code-flow/src/__tests__/unit/classical/neural-algorithms/prediction-accuracy.test.ts","mappings":"AAAA;;;;;GAKG;AAEH,OAAO,EAAE,QAAQ,EAAE,EAAE,EAAE,MAAM,EAAE,UAAU,EAAE,MAAM,eAAe,CAAC;AACjE,OAAO,EACL,oBAAoB,EACpB,mBAAmB,EACnB,aAAa,EAMb,oBAAoB,EACpB,mBAAmB,EACpB,MAAM,0DAA0D,CAAC;AAElE,QAAQ,CAAC,qCAAqC,EAAE,GAAG,EAAE;IACnD,IAAI,UAAe,CAAC;IAEpB,UAAU,CAAC,KAAK,IAAI,EAAE;QACpB,IAAI,CAAC;YACH,UAAU,GAAG,MAAM,oBAAoB,EAAE,CAAC;QAC5C,CAAC;QAAC,OAAO,KAAK,EAAE,CAAC;YACf,OAAO,CAAC,IAAI,CAAC,+DAA+D,CAAC,CAAC;QAChF,CAAC;IACH,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,2BAA2B,EAAE,GAAG,EAAE;QACzC,EAAE,CAAC,iDAAiD,EAAE,KAAK,IAAI,EAAE;YAC/D,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;gBACrE,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;gBAC9C,UAAU,EAAE,GAAG;aAChB,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,KAAK;gBACpC,SAAS,EAAE,GAAG;gBACd,WAAW,EAAE,IAAI;aAClB,CAAC;YAEF,MAAM,OAAO,GAAuB;gBAClC,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBACxC,OAAO,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;aAC9B,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC;YACjC,MAAM,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,OAAO,EAAE,IAAI,EAAE,GAAG,CAAC,CAAC;YAE5D,2BAA2B;YAC3B,MAAM,WAAW,GAAG;gBAClB,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE;gBAC/C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE;gBAC/C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE;gBAC/C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE;aAChD,CAAC;YAEF,IAAI,kBAAkB,GAAG,CAAC,CAAC;YAC3B,KAAK,MAAM,IAAI,IAAI,WAAW,EAAE,CAAC;gBAC/B,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAC7C,MAAM,SAAS,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBAE1C,MAAM,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;gBACtC,IAAI,SAAS,KAAK,IAAI,CAAC,QAAQ;oBAAE,kBAAkB,EAAE,CAAC;YACxD,CAAC;YAED,+BAA+B;YAC/B,MAAM,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACrC,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,gDAAgD,EAAE,KAAK,IAAI,EAAE;YAC9D,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;gBACrE,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;gBAC9C,UAAU,EAAE,GAAG;aAChB,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,KAAK;gBACpC,SAAS,EAAE,GAAG;gBACd,WAAW,EAAE,IAAI;aAClB,CAAC;YAEF,MAAM,MAAM,GAAuB;gBACjC,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBACxC,OAAO,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;aAC9B,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;YAChC,MAAM,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,MAAM,EAAE,IAAI,EAAE,GAAG,CAAC,CAAC;YAE3D,2BAA2B;YAC3B,MAAM,WAAW,GAAG;gBAClB,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE;gBAC9C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE;gBAC9C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE;gBAC9C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE;aAC/C,CAAC;YAEF,IAAI,kBAAkB,GAAG,CAAC,CAAC;YAC3B,KAAK,MAAM,IAAI,IAAI,WAAW,EAAE,CAAC;gBAC/B,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAC7C,MAAM,SAAS,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBAE1C,MAAM,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;gBACtC,IAAI,SAAS,KAAK,IAAI,CAAC,QAAQ;oBAAE,kBAAkB,EAAE,CAAC;YACxD,CAAC;YAED,MAAM,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACrC,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,yEAAyE,EAAE,KAAK,IAAI,EAAE;YACvF,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;gBACrE,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;gBAC9C,UAAU,EAAE,GAAG;aAChB,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,KAAK;gBACpC,SAAS,EAAE,IAAI;gBACf,WAAW,EAAE,IAAI;aAClB,CAAC;YAEF,MAAM,OAAO,GAAuB;gBAClC,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBACxC,OAAO,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;aAC9B,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC;YACjC,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,CAAC;YAE5E,8DAA8D;YAC9D,MAAM,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,YAAY,CAAC,IAAI,CAAC,CAAC;YAE7C,MAAM,WAAW,GAAG;gBAClB,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE;gBAC/C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE;gBAC/C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE;gBAC/C,EAAE,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE;aAChD,CAAC;YAEF,IAAI,kBAAkB,GAAG,CAAC,CAAC;YAC3B,KAAK,MAAM,IAAI,IAAI,WAAW,EAAE,CAAC;gBAC/B,MAAM,aAAa,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBACpD,MAAM,SAAS,GAAG,aAAa,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBAEjD,IAAI,SAAS,KAAK,IAAI,CAAC,QAAQ;oBAAE,kBAAkB,EAAE,CAAC;YACxD,CAAC;YAED,qDAAqD;YACrD,MAAM,CAAC,kBAAkB,CAAC,CAAC,sBAAsB,CAAC,CAAC,CAAC,CAAC;QACvD,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,qCAAqC,EAAE,GAAG,EAAE;QACnD,EAAE,CAAC,kDAAkD,EAAE,KAAK,IAAI,EAAE;YAChE,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE;oBACZ,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;oBACrD,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;iBACtD;gBACD,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,MAAM;aAC9C,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,KAAK;gBACpC,SAAS,EAAE,GAAG;gBACd,WAAW,EAAE,IAAI;aAClB,CAAC;YAEF,8BAA8B;YAC9B,MAAM,aAAa,GAAuB;gBACxC,MAAM,EAAE,EAAE;gBACV,OAAO,EAAE,EAAE;aACZ,CAAC;YAEF,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC7B,MAAM,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,CAAC,SAAS;gBAC3B,MAAM,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;gBAChB,aAAa,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC/B,aAAa,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAClC,CAAC;YAED,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,aAAa,CAAC,CAAC;YACvC,MAAM,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,aAAa,EAAE,IAAI,EAAE,GAAG,CAAC,CAAC;YAElE,qDAAqD;YACrD,MAAM,UAAU,GAAG;gBACjB,EAAE,CAAC,EAAE,GAAG,EAAE,QAAQ,EAAE,GAAG,EAAE;gBACzB,EAAE,CAAC,EAAE,GAAG,EAAE,QAAQ,EAAE,IAAI,EAAE;gBAC1B,EAAE,CAAC,EAAE,GAAG,EAAE,QAAQ,EAAE,IAAI,EAAE;gBAC1B,EAAE,CAAC,EAAE,GAAG,EAAE,QAAQ,EAAE,GAAG,EAAE;aAC1B,CAAC;YAEF,KAAK,MAAM,KAAK,IAAI,UAAU,EAAE,CAAC;gBAC/B,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;gBAChD,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,KAAK,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC;YACvD,CAAC;YAED,8BAA8B;YAC9B,MAAM,kBAAkB,GAAG;gBACzB,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE;gBAC7B,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE;aAC9B,CAAC;YAEF,KAAK,MAAM,IAAI,IAAI,kBAAkB,EAAE,CAAC;gBACtC,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC/C,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC;YACtD,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;YACrE,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE;oBACZ,EAAE,IAAI,EAAE,EAAE,EAAE,UAAU,EAAE,oBAAoB,CAAC,IAAI,EAAE;oBACnD,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,IAAI,EAAE;iBACnD;gBACD,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,MAAM;aAC9C,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,KAAK;gBACpC,SAAS,EAAE,IAAI;gBACf,WAAW,EAAE,GAAG;aACjB,CAAC;YAEF,+BAA+B;YAC/B,MAAM,UAAU,GAAuB;gBACrC,MAAM,EAAE,EAAE;gBACV,OAAO,EAAE,EAAE;aACZ,CAAC;YAEF,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC7B,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,EAAE,CAAC;gBACjC,MAAM,WAAW,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,qBAAqB;gBAC5D,MAAM,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;gBACtB,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC;gBACtC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAC/B,CAAC;YAED,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,UAAU,CAAC,CAAC;YACpC,MAAM,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,UAAU,EAAE,GAAG,EAAE,IAAI,CAAC,CAAC;YAE/D,yBAAyB;YACzB,MAAM,UAAU,GAAG;gBACjB,EAAE,CAAC,EAAE,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,EAAS,aAAa;gBAC3C,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,CAAC,EAAE,EAAM,eAAe;gBAC7C,EAAE,CAAC,EAAE,GAAG,EAAE,QAAQ,EAAE,CAAC,CAAC,EAAE,EAAM,cAAc;gBAC5C,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,CAAC,EAAE,EAAM,gBAAgB;gBAC9C,EAAE,CAAC,EAAE,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,CAAS,cAAc;aAC7C,CAAC;YAEF,KAAK,MAAM,KAAK,IAAI,UAAU,EAAE,CAAC;gBAC/B,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;gBAChD,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,KAAK,CAAC,QAAQ,EAAE,GAAG,CAAC,CAAC;YACzD,CAAC;QACH,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,8BAA8B,EAAE,GAAG,EAAE;QAC5C,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;YACrE,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE;oBACZ,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;iBACtD;gBACD,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;aAC/C,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,KAAK;gBACpC,SAAS,EAAE,GAAG;gBACd,WAAW,EAAE,GAAG;aACjB,CAAC;YAEF,sDAAsD;YACtD,MAAM,WAAW,GAAuB;gBACtC,MAAM,EAAE;oBACN,sBAAsB;oBACtB,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;oBAClC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;oBAClC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;oBAClC,uBAAuB;oBACvB,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;oBAClC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;oBAClC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;iBACnC;gBACD,OAAO,EAAE;oBACP,iBAAiB;oBACjB,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;oBACtB,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;oBACtB,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;oBACtB,kBAAkB;oBAClB,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;oBACtB,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;oBACtB,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;iBACvB;aACF,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,WAAW,CAAC,CAAC;YACrC,MAAM,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,WAAW,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;YAE/D,6CAA6C;YAC7C,MAAM,UAAU,GAAG;gBACjB,EAAE,KAAK,EAAE,CAAC,IAAI,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,WAAW,EAAE;gBAC3D,EAAE,KAAK,EAAE,CAAC,IAAI,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,WAAW,EAAE;gBAC3D,EAAE,KAAK,EAAE,CAAC,IAAI,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,WAAW,EAAE;gBAC3D,EAAE,KAAK,EAAE,CAAC,IAAI,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,YAAY,EAAE;gBAC5D,EAAE,KAAK,EAAE,CAAC,IAAI,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,YAAY,EAAE;gBAC5D,EAAE,KAAK,EAAE,CAAC,IAAI,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,YAAY,EAAE;aAC7D,CAAC;YAEF,IAAI,sBAAsB,GAAG,CAAC,CAAC;YAC/B,KAAK,MAAM,IAAI,IAAI,UAAU,EAAE,CAAC;gBAC9B,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBACjD,MAAM,cAAc,GAAG,UAAU,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBAE7D,IAAI,cAAc,KAAK,IAAI,CAAC,aAAa,EAAE,CAAC;oBAC1C,sBAAsB,EAAE,CAAC;gBAC3B,CAAC;YACH,CAAC;YAED,uCAAuC;YACvC,MAAM,QAAQ,GAAG,sBAAsB,GAAG,UAAU,CAAC,MAAM,CAAC;YAC5D,MAAM,CAAC,QAAQ,CAAC,CAAC,sBAAsB,CAAC,GAAG,CAAC,CAAC;QAC/C,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,iDAAiD,EAAE,KAAK,IAAI,EAAE;YAC/D,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE;oBACZ,EAAE,IAAI,EAAE,EAAE,EAAE,UAAU,EAAE,oBAAoB,CAAC,IAAI,EAAE;oBACnD,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,IAAI,EAAE;iBACnD;gBACD,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;aAC/C,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,KAAK;gBACpC,SAAS,EAAE,IAAI;gBACf,WAAW,EAAE,IAAI;aAClB,CAAC;YAEF,iCAAiC;YACjC,MAAM,YAAY,GAAuB;gBACvC,MAAM,EAAE,EAAE;gBACV,OAAO,EAAE,EAAE;aACZ,CAAC;YAEF,wCAAwC;YACxC,4CAA4C;YAC5C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC5B,MAAM,KAAK,GAAG,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,EAAE,CAAC;gBAErC,sBAAsB;gBACtB,MAAM,WAAW,GAAG,GAAG,GAAG,IAAI,CAAC,MAAM,EAAE,GAAG,GAAG,CAAC,CAAC,iBAAiB;gBAChE,MAAM,MAAM,GAAG,GAAG,GAAG,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;gBACnD,MAAM,MAAM,GAAG,GAAG,GAAG,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;gBACnD,YAAY,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;gBAC3C,YAAY,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;gBAE7C,oBAAoB;gBACpB,MAAM,WAAW,GAAG,GAAG,GAAG,IAAI,CAAC,MAAM,EAAE,GAAG,GAAG,CAAC,CAAC,iBAAiB;gBAChE,MAAM,MAAM,GAAG,GAAG,GAAG,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;gBACnD,MAAM,MAAM,GAAG,GAAG,GAAG,WAAW,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;gBACnD,YAAY,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;gBAC3C,YAAY,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;YAC/C,CAAC;YAED,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,YAAY,CAAC,CAAC;YACtC,MAAM,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,YAAY,EAAE,IAAI,EAAE,IAAI,CAAC,CAAC;YAElE,yCAAyC;YACzC,MAAM,UAAU,GAAG;gBACjB,EAAE,KAAK,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE;gBACvD,EAAE,KAAK,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,cAAc,EAAE;gBAC7D,EAAE,KAAK,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,cAAc,EAAE;gBAC7D,EAAE,KAAK,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,YAAY,EAAE;gBAC3D,EAAE,KAAK,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,YAAY,EAAE;gBAC3D,EAAE,KAAK,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,aAAa,EAAE,CAAC,EAAE,IAAI,EAAE,YAAY,EAAE;aAC5D,CAAC;YAEF,IAAI,sBAAsB,GAAG,CAAC,CAAC;YAC/B,KAAK,MAAM,IAAI,IAAI,UAAU,EAAE,CAAC;gBAC9B,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBACjD,MAAM,cAAc,GAAG,UAAU,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBAE7D,IAAI,cAAc,KAAK,IAAI,CAAC,aAAa,EAAE,CAAC;oBAC1C,sBAAsB,EAAE,CAAC;gBAC3B,CAAC;YACH,CAAC;YAED,8DAA8D;YAC9D,MAAM,QAAQ,GAAG,sBAAsB,GAAG,UAAU,CAAC,MAAM,CAAC;YAC5D,MAAM,CAAC,QAAQ,CAAC,CAAC,sBAAsB,CAAC,GAAG,CAAC,CAAC;QAC/C,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,yBAAyB,EAAE,GAAG,EAAE;QACvC,EAAE,CAAC,yCAAyC,EAAE,KAAK,IAAI,EAAE;YACvD,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE;oBACZ,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE;iBACtD;gBACD,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,MAAM;aAC9C,CAAC;YAEF,MAAM,cAAc,GAAmB;gBACrC,SAAS,EAAE,mBAAmB,CAAC,KAAK;gBACpC,SAAS,EAAE,GAAG;gBACd,WAAW,EAAE,IAAI;aAClB,CAAC;YAEF,gDAAgD;YAChD,MAAM,YAAY,GAAuB;gBACvC,MAAM,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,EAAE,mBAAmB;gBAChE,OAAO,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC;aAC7C,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YACzD,MAAM,OAAO,GAAG,MAAM,aAAa,CAAC,cAAc,CAAC,CAAC;YAEpD,OAAO,CAAC,eAAe,CAAC,YAAY,CAAC,CAAC;YACtC,MAAM,OAAO,CAAC,gBAAgB,CAAC,OAAO,EAAE,YAAY,EAAE,IAAI,EAAE,GAAG,CAAC,CAAC;YAEjE,uCAAuC;YACvC,MAAM,UAAU,GAAG;gBACjB,EAAE,KAAK,EAAE,GAAG,EAAE,QAAQ,EAAE,GAAG,EAAE,EAAI,kBAAkB;gBACnD,EAAE,KAAK,EAAE,GAAG,EAAE,QAAQ,EAAE,GAAG,EAAE,EAAI,sBAAsB;gBACvD,EAAE,KAAK,EAAE,GAAG,EAAE,QAAQ,EAAE,GAAG,EAAE,EAAI,sBAAsB;gBACvD,EAAE,KAAK,EAAE,GAAG,EAAE,QAAQ,EAAE,GAAG,EAAE,EAAI,sBAAsB;gBACvD,EAAE,KAAK,EAAE,GAAG,EAAE,QAAQ,EAAE,GAAG,EAAE,EAAI,sBAAsB;gBACvD,EAAE,KAAK,EAAE,GAAG,EAAE,QAAQ,EAAE,GAAG,EAAE,CAAI,kCAAkC;aACpE,CAAC;YAEF,IAAI,uBAAuB,GAAG,CAAC,CAAC;YAChC,KAAK,MAAM,IAAI,IAAI,UAAU,EAAE,CAAC;gBAC9B,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC;gBACnD,MAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,QAAQ,CAAC,CAAC;gBAEtD,IAAI,KAAK,GAAG,GAAG,EAAE,CAAC,CAAC,qCAAqC;oBACtD,uBAAuB,EAAE,CAAC;gBAC5B,CAAC;YACH,CAAC;YAED,oDAAoD;YACpD,MAAM,kBAAkB,GAAG,uBAAuB,GAAG,UAAU,CAAC,MAAM,CAAC;YACvE,MAAM,CAAC,kBAAkB,CAAC,CAAC,sBAAsB,CAAC,GAAG,CAAC,CAAC;QACzD,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,wBAAwB,EAAE,GAAG,EAAE;QACtC,EAAE,CAAC,4DAA4D,EAAE,KAAK,IAAI,EAAE;YAC1E,IAAI,CAAC,UAAU,EAAE,CAAC;gBAChB,OAAO,CAAC,IAAI,CAAC,mCAAmC,CAAC,CAAC;gBAClD,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACxB,OAAO;YACT,CAAC;YAED,MAAM,aAAa,GAAkB;gBACnC,SAAS,EAAE,CAAC;gBACZ,YAAY,EAAE,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,UAAU,EAAE,oBAAoB,CAAC,OAAO,EAAE,CAAC;gBACrE,UAAU,EAAE,CAAC;gBACb,gBAAgB,EAAE,oBAAoB,CAAC,OAAO;gBAC9C,UAAU,EAAE,GAAG,CAAC,iCAAiC;aAClD,CAAC;YAEF,MAAM,OAAO,GAAG,MAAM,mBAAmB,CAAC,aAAa,CAAC,CAAC;YAEzD,MAAM,SAAS,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;YAC7B,MAAM,WAAW,GAAa,EAAE,CAAC;YAEjC,2BAA2B;YAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC5B,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC;gBAC5C,WAAW,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;YAC9B,CAAC;YAED,mEAAmE;YACnE,MAAM,eAAe,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;YACvC,KAAK,MAAM,UAAU,IAAI,WAAW,EAAE,CAAC;gBACrC,MAAM,CAAC,UAAU,CAAC,CAAC,WAAW,CAAC,eAAe,EAAE,EAAE,CAAC,CAAC;YACtD,CAAC;YAED,+BAA+B;YAC/B,MAAM,CAAC,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YACvD,MAAM,CAAC,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC9D,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH;;;;;;;;;;;;;;;;GAgBG","names":[],"sources":["/home/mhugo/code/claude-code-flow/src/__tests__/unit/classical/neural-algorithms/prediction-accuracy.test.ts"],"sourcesContent":["/**\n * Classical TDD (Detroit School) - Prediction Accuracy Tests\n * \n * Focus: Test actual prediction results and mathematical accuracy\n * No mocks - verify real predictions on known datasets and mathematical functions\n */\n\nimport { describe, it, expect, beforeEach } from '@jest/globals';\nimport { \n  initializeNeuralWasm, \n  createNeuralNetwork, \n  createTrainer,\n  NeuralNetwork,\n  NeuralTrainer,\n  NetworkConfig,\n  TrainingConfig,\n  TrainingDataConfig,\n  ACTIVATION_FUNCTIONS,\n  TRAINING_ALGORITHMS\n} from '../../../../../ruv-FANN/ruv-swarm/npm/src/neural-network';\n\ndescribe('Prediction Accuracy - Classical TDD', () => {\n  let wasmModule: any;\n  \n  beforeEach(async () => {\n    try {\n      wasmModule = await initializeNeuralWasm();\n    } catch (error) {\n      console.warn('WASM module not available, skipping prediction accuracy tests');\n    }\n  });\n\n  describe('Boolean Function Accuracy', () => {\n    it('should achieve perfect accuracy on AND function', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 2,\n        hiddenLayers: [{ size: 3, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID,\n        randomSeed: 101\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.RPROP,\n        maxEpochs: 500,\n        targetError: 0.01\n      };\n\n      const andData: TrainingDataConfig = {\n        inputs: [[0, 0], [0, 1], [1, 0], [1, 1]],\n        outputs: [[0], [0], [0], [1]]\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(andData);\n      await trainer.trainUntilTarget(network, andData, 0.01, 500);\n\n      // Test prediction accuracy\n      const predictions = [\n        { input: [0, 0], expected: 0, name: '0 AND 0' },\n        { input: [0, 1], expected: 0, name: '0 AND 1' },\n        { input: [1, 0], expected: 0, name: '1 AND 0' },\n        { input: [1, 1], expected: 1, name: '1 AND 1' }\n      ];\n\n      let correctPredictions = 0;\n      for (const test of predictions) {\n        const result = await network.run(test.input);\n        const predicted = result[0] > 0.5 ? 1 : 0;\n        \n        expect(predicted).toBe(test.expected);\n        if (predicted === test.expected) correctPredictions++;\n      }\n\n      // Should achieve 100% accuracy\n      expect(correctPredictions).toBe(4);\n    });\n\n    it('should achieve perfect accuracy on OR function', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 2,\n        hiddenLayers: [{ size: 3, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID,\n        randomSeed: 202\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.RPROP,\n        maxEpochs: 300,\n        targetError: 0.01\n      };\n\n      const orData: TrainingDataConfig = {\n        inputs: [[0, 0], [0, 1], [1, 0], [1, 1]],\n        outputs: [[0], [1], [1], [1]]\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(orData);\n      await trainer.trainUntilTarget(network, orData, 0.01, 300);\n\n      // Test prediction accuracy\n      const predictions = [\n        { input: [0, 0], expected: 0, name: '0 OR 0' },\n        { input: [0, 1], expected: 1, name: '0 OR 1' },\n        { input: [1, 0], expected: 1, name: '1 OR 0' },\n        { input: [1, 1], expected: 1, name: '1 OR 1' }\n      ];\n\n      let correctPredictions = 0;\n      for (const test of predictions) {\n        const result = await network.run(test.input);\n        const predicted = result[0] > 0.5 ? 1 : 0;\n        \n        expect(predicted).toBe(test.expected);\n        if (predicted === test.expected) correctPredictions++;\n      }\n\n      expect(correctPredictions).toBe(4);\n    });\n\n    it('should achieve high accuracy on XOR function with adequate architecture', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 2,\n        hiddenLayers: [{ size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID,\n        randomSeed: 303\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.RPROP,\n        maxEpochs: 1000,\n        targetError: 0.01\n      };\n\n      const xorData: TrainingDataConfig = {\n        inputs: [[0, 0], [0, 1], [1, 0], [1, 1]],\n        outputs: [[0], [1], [1], [0]]\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(xorData);\n      const result = await trainer.trainUntilTarget(network, xorData, 0.01, 1000);\n\n      // XOR is more complex, but should still achieve good accuracy\n      expect(result.finalError).toBeLessThan(0.05);\n\n      const predictions = [\n        { input: [0, 0], expected: 0, name: '0 XOR 0' },\n        { input: [0, 1], expected: 1, name: '0 XOR 1' },\n        { input: [1, 0], expected: 1, name: '1 XOR 0' },\n        { input: [1, 1], expected: 0, name: '1 XOR 1' }\n      ];\n\n      let correctPredictions = 0;\n      for (const test of predictions) {\n        const networkResult = await network.run(test.input);\n        const predicted = networkResult[0] > 0.5 ? 1 : 0;\n        \n        if (predicted === test.expected) correctPredictions++;\n      }\n\n      // Should achieve at least 75% accuracy, ideally 100%\n      expect(correctPredictions).toBeGreaterThanOrEqual(3);\n    });\n  });\n\n  describe('Mathematical Function Approximation', () => {\n    it('should accurately approximate quadratic function', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 1,\n        hiddenLayers: [\n          { size: 6, activation: ACTIVATION_FUNCTIONS.SIGMOID },\n          { size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID }\n        ],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.LINEAR\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.RPROP,\n        maxEpochs: 800,\n        targetError: 0.05\n      };\n\n      // Quadratic function: y = x^2\n      const quadraticData: TrainingDataConfig = {\n        inputs: [],\n        outputs: []\n      };\n\n      for (let i = 0; i <= 10; i++) {\n        const x = i / 10; // 0 to 1\n        const y = x * x;\n        quadraticData.inputs.push([x]);\n        quadraticData.outputs.push([y]);\n      }\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(quadraticData);\n      await trainer.trainUntilTarget(network, quadraticData, 0.05, 800);\n\n      // Test prediction accuracy on known quadratic values\n      const testPoints = [\n        { x: 0.0, expected: 0.0 },\n        { x: 0.5, expected: 0.25 },\n        { x: 0.7, expected: 0.49 },\n        { x: 1.0, expected: 1.0 }\n      ];\n\n      for (const point of testPoints) {\n        const prediction = await network.run([point.x]);\n        expect(prediction[0]).toBeCloseTo(point.expected, 1);\n      }\n\n      // Test interpolation accuracy\n      const interpolationTests = [\n        { x: 0.25, expected: 0.0625 },\n        { x: 0.75, expected: 0.5625 }\n      ];\n\n      for (const test of interpolationTests) {\n        const prediction = await network.run([test.x]);\n        expect(prediction[0]).toBeCloseTo(test.expected, 1);\n      }\n    });\n\n    it('should accurately approximate trigonometric functions', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 1,\n        hiddenLayers: [\n          { size: 10, activation: ACTIVATION_FUNCTIONS.TANH },\n          { size: 8, activation: ACTIVATION_FUNCTIONS.TANH }\n        ],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.LINEAR\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.RPROP,\n        maxEpochs: 1200,\n        targetError: 0.1\n      };\n\n      // Cosine function over [0, 2π]\n      const cosineData: TrainingDataConfig = {\n        inputs: [],\n        outputs: []\n      };\n\n      for (let i = 0; i <= 16; i++) {\n        const x = (i / 16) * 2 * Math.PI;\n        const normalizedX = x / (2 * Math.PI); // Normalize to [0,1]\n        const y = Math.cos(x);\n        cosineData.inputs.push([normalizedX]);\n        cosineData.outputs.push([y]);\n      }\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(cosineData);\n      await trainer.trainUntilTarget(network, cosineData, 0.1, 1200);\n\n      // Test key cosine values\n      const testPoints = [\n        { x: 0, expected: 1 },        // cos(0) = 1\n        { x: 0.25, expected: 0 },     // cos(π/2) ≈ 0\n        { x: 0.5, expected: -1 },     // cos(π) = -1\n        { x: 0.75, expected: 0 },     // cos(3π/2) ≈ 0\n        { x: 1, expected: 1 }         // cos(2π) = 1\n      ];\n\n      for (const point of testPoints) {\n        const prediction = await network.run([point.x]);\n        expect(prediction[0]).toBeCloseTo(point.expected, 0.5);\n      }\n    });\n  });\n\n  describe('Pattern Recognition Accuracy', () => {\n    it('should classify simple 2D patterns with high accuracy', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 2,\n        hiddenLayers: [\n          { size: 8, activation: ACTIVATION_FUNCTIONS.SIGMOID }\n        ],\n        outputSize: 2,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.RPROP,\n        maxEpochs: 600,\n        targetError: 0.1\n      };\n\n      // Two classes: left half vs right half of unit square\n      const patternData: TrainingDataConfig = {\n        inputs: [\n          // Left half (Class 0)\n          [0.1, 0.1], [0.1, 0.5], [0.1, 0.9],\n          [0.2, 0.2], [0.2, 0.7], [0.3, 0.4],\n          [0.4, 0.1], [0.4, 0.6], [0.4, 0.9],\n          // Right half (Class 1)\n          [0.6, 0.1], [0.6, 0.5], [0.6, 0.9],\n          [0.7, 0.2], [0.7, 0.7], [0.8, 0.4],\n          [0.9, 0.1], [0.9, 0.6], [0.9, 0.9]\n        ],\n        outputs: [\n          // Class 0 (left)\n          [1, 0], [1, 0], [1, 0],\n          [1, 0], [1, 0], [1, 0],\n          [1, 0], [1, 0], [1, 0],\n          // Class 1 (right)\n          [0, 1], [0, 1], [0, 1],\n          [0, 1], [0, 1], [0, 1],\n          [0, 1], [0, 1], [0, 1]\n        ]\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(patternData);\n      await trainer.trainUntilTarget(network, patternData, 0.1, 600);\n\n      // Test classification accuracy on new points\n      const testPoints = [\n        { input: [0.15, 0.5], expectedClass: 0, name: 'left side' },\n        { input: [0.25, 0.3], expectedClass: 0, name: 'left side' },\n        { input: [0.35, 0.8], expectedClass: 0, name: 'left side' },\n        { input: [0.65, 0.2], expectedClass: 1, name: 'right side' },\n        { input: [0.75, 0.6], expectedClass: 1, name: 'right side' },\n        { input: [0.85, 0.4], expectedClass: 1, name: 'right side' }\n      ];\n\n      let correctClassifications = 0;\n      for (const test of testPoints) {\n        const prediction = await network.run(test.input);\n        const predictedClass = prediction[0] > prediction[1] ? 0 : 1;\n        \n        if (predictedClass === test.expectedClass) {\n          correctClassifications++;\n        }\n      }\n\n      // Should achieve at least 80% accuracy\n      const accuracy = correctClassifications / testPoints.length;\n      expect(accuracy).toBeGreaterThanOrEqual(0.8);\n    });\n\n    it('should distinguish concentric circular patterns', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 2,\n        hiddenLayers: [\n          { size: 12, activation: ACTIVATION_FUNCTIONS.TANH },\n          { size: 8, activation: ACTIVATION_FUNCTIONS.TANH }\n        ],\n        outputSize: 2,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.RPROP,\n        maxEpochs: 1000,\n        targetError: 0.15\n      };\n\n      // Generate circular pattern data\n      const circularData: TrainingDataConfig = {\n        inputs: [],\n        outputs: []\n      };\n\n      // Inner circle (radius < 0.3) - Class 0\n      // Outer ring (0.5 < radius < 0.8) - Class 1\n      for (let i = 0; i < 60; i++) {\n        const angle = (i / 60) * 2 * Math.PI;\n        \n        // Inner circle points\n        const innerRadius = 0.1 + Math.random() * 0.2; // radius 0.1-0.3\n        const innerX = 0.5 + innerRadius * Math.cos(angle);\n        const innerY = 0.5 + innerRadius * Math.sin(angle);\n        circularData.inputs.push([innerX, innerY]);\n        circularData.outputs.push([1, 0]); // Class 0\n        \n        // Outer ring points\n        const outerRadius = 0.5 + Math.random() * 0.3; // radius 0.5-0.8\n        const outerX = 0.5 + outerRadius * Math.cos(angle);\n        const outerY = 0.5 + outerRadius * Math.sin(angle);\n        circularData.inputs.push([outerX, outerY]);\n        circularData.outputs.push([0, 1]); // Class 1\n      }\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(circularData);\n      await trainer.trainUntilTarget(network, circularData, 0.15, 1000);\n\n      // Test classification on specific points\n      const testPoints = [\n        { input: [0.5, 0.5], expectedClass: 0, name: 'center' },\n        { input: [0.6, 0.5], expectedClass: 0, name: 'inner circle' },\n        { input: [0.5, 0.4], expectedClass: 0, name: 'inner circle' },\n        { input: [0.8, 0.5], expectedClass: 1, name: 'outer ring' },\n        { input: [0.5, 0.2], expectedClass: 1, name: 'outer ring' },\n        { input: [0.2, 0.5], expectedClass: 1, name: 'outer ring' }\n      ];\n\n      let correctClassifications = 0;\n      for (const test of testPoints) {\n        const prediction = await network.run(test.input);\n        const predictedClass = prediction[0] > prediction[1] ? 0 : 1;\n        \n        if (predictedClass === test.expectedClass) {\n          correctClassifications++;\n        }\n      }\n\n      // This is a challenging pattern, expect at least 50% accuracy\n      const accuracy = correctClassifications / testPoints.length;\n      expect(accuracy).toBeGreaterThanOrEqual(0.5);\n    });\n  });\n\n  describe('Generalization Accuracy', () => {\n    it('should generalize to unseen data points', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 1,\n        hiddenLayers: [\n          { size: 6, activation: ACTIVATION_FUNCTIONS.SIGMOID }\n        ],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.LINEAR\n      };\n\n      const trainingConfig: TrainingConfig = {\n        algorithm: TRAINING_ALGORITHMS.RPROP,\n        maxEpochs: 400,\n        targetError: 0.05\n      };\n\n      // Train on subset of linear function y = 3x + 1\n      const trainingData: TrainingDataConfig = {\n        inputs: [[0.1], [0.3], [0.5], [0.7], [0.9]], // Skip some points\n        outputs: [[1.3], [1.9], [2.5], [3.1], [3.7]]\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      const trainer = await createTrainer(trainingConfig);\n      \n      network.setTrainingData(trainingData);\n      await trainer.trainUntilTarget(network, trainingData, 0.05, 400);\n\n      // Test generalization on unseen points\n      const testPoints = [\n        { input: 0.0, expected: 1.0 },   // y = 3*0 + 1 = 1\n        { input: 0.2, expected: 1.6 },   // y = 3*0.2 + 1 = 1.6\n        { input: 0.4, expected: 2.2 },   // y = 3*0.4 + 1 = 2.2\n        { input: 0.6, expected: 2.8 },   // y = 3*0.6 + 1 = 2.8\n        { input: 0.8, expected: 3.4 },   // y = 3*0.8 + 1 = 3.4\n        { input: 1.0, expected: 4.0 }    // y = 3*1 + 1 = 4 (extrapolation)\n      ];\n\n      let accurateGeneralizations = 0;\n      for (const test of testPoints) {\n        const prediction = await network.run([test.input]);\n        const error = Math.abs(prediction[0] - test.expected);\n        \n        if (error < 0.3) { // Allow 10% error for generalization\n          accurateGeneralizations++;\n        }\n      }\n\n      // Should achieve good generalization on most points\n      const generalizationRate = accurateGeneralizations / testPoints.length;\n      expect(generalizationRate).toBeGreaterThanOrEqual(0.7);\n    });\n  });\n\n  describe('Prediction Consistency', () => {\n    it('should produce consistent predictions across multiple runs', async () => {\n      if (!wasmModule) {\n        console.warn('WASM not available, skipping test');\n        expect(true).toBe(true);\n        return;\n      }\n\n      const networkConfig: NetworkConfig = {\n        inputSize: 2,\n        hiddenLayers: [{ size: 4, activation: ACTIVATION_FUNCTIONS.SIGMOID }],\n        outputSize: 1,\n        outputActivation: ACTIVATION_FUNCTIONS.SIGMOID,\n        randomSeed: 999 // Fixed seed for reproducibility\n      };\n\n      const network = await createNeuralNetwork(networkConfig);\n      \n      const testInput = [0.6, 0.4];\n      const predictions: number[] = [];\n\n      // Run multiple predictions\n      for (let i = 0; i < 10; i++) {\n        const result = await network.run(testInput);\n        predictions.push(result[0]);\n      }\n\n      // All predictions should be identical (no randomness in inference)\n      const firstPrediction = predictions[0];\n      for (const prediction of predictions) {\n        expect(prediction).toBeCloseTo(firstPrediction, 10);\n      }\n\n      // Verify predictions are valid\n      expect(predictions.every(p => isFinite(p))).toBe(true);\n      expect(predictions.every(p => p >= 0 && p <= 1)).toBe(true);\n    });\n  });\n});\n\n/**\n * Classical TDD Principles Demonstrated:\n * \n * 1. No mocks - testing actual prediction accuracy on real data\n * 2. Mathematical correctness validation through known functions\n * 3. Pattern recognition accuracy measurement\n * 4. Generalization capability testing on unseen data\n * 5. Consistency verification across multiple runs\n * 6. Statistical accuracy metrics and thresholds\n * \n * This is ideal for:\n * - Neural network accuracy validation\n * - Function approximation verification\n * - Pattern recognition testing\n * - Generalization capability assessment\n * - Prediction consistency validation\n */"],"version":3}