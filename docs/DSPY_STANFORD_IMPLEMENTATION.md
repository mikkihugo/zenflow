# DSPy TypeScript Library - Stanford DSPy Complete Port

A complete TypeScript implementation of Stanford's DSPy (Declarative Self-improving Language Programs) framework, integrated with @zen-ai/shared infrastructure for production use.

## ğŸš€ Overview

This library provides a full production-ready port of Stanford DSPy's sophisticated prompt optimization algorithms, including:

- **LabeledFewShot**: Simple k-shot example selection
- **BootstrapFewShot**: Advanced teacher/student bootstrapping with validation
- **MIPROv2**: Multi-objective instruction proposal with Bayesian optimization
- **Ensemble**: Multi-model combination and optimization strategies

## ğŸ“¦ Features

### Core Stanford DSPy Algorithms

- âœ… **Complete Teleprompter Architecture** - Abstract base class with full Stanford compatibility
- âœ… **LabeledFewShot** - Random k-shot example selection with seeded reproducibility
- âœ… **BootstrapFewShot** - Sophisticated bootstrapping with teacher models and validation metrics
- âœ… **MIPROv2** - Most advanced Stanford algorithm with instruction proposal and Bayesian optimization
- âœ… **Ensemble** - Multi-teleprompter combination with custom reduction functions

### Production Features

- âœ… **@zen-ai/shared Integration** - LLM, logging, storage, and configuration services
- âœ… **Standalone Operation** - Graceful fallback when shared services unavailable
- âœ… **TypeScript Strict Mode** - Full type safety with ES2022 compilation target
- âœ… **Performance Tracking** - Built-in metrics, logging, and optimization statistics
- âœ… **Seeded Reproducibility** - Deterministic results for consistent testing

### Advanced Capabilities

- âœ… **Program Builder** - Fluent API for creating DSPy programs
- âœ… **Signature System** - Input/output field specifications with type validation
- âœ… **Trace System** - Execution path capture for debugging and analysis
- âœ… **Metric Framework** - Custom evaluation metrics with threshold support
- âœ… **Minibatch Optimization** - Efficient evaluation for large datasets

## ğŸ› ï¸ Installation

```bash
# Already included in claude-code-zen
# Optional: Install @zen-ai/shared for enhanced features
npm install @zen-ai/shared
```

## ğŸ“– Quick Start

### Basic Usage

```typescript
import {
  LabeledFewShot,
  BootstrapFewShot,
  MIPROv2,
  createProgram,
  createSignature,
  createExamples,
} from '../lib/dspy';

// Create training data
const trainset = createExamples([
  {
    input: { question: 'What is the capital of France?' },
    output: { answer: 'Paris', reasoning: 'Paris is the capital of France.' },
  },
  // ... more examples
]);

// Define task signature
const qaSignature = createSignature(
  'Question Answering',
  { question: 'The question to answer' },
  { answer: 'Direct answer', reasoning: 'Explanation' },
  'Answer questions accurately with clear reasoning.'
);

// Create DSPy program
const program = createProgram().addPredictor('qa', qaSignature).build();

// Optimize with Stanford algorithms
const teleprompter = new MIPROv2({
  auto: 'light',
  metric: (example, prediction, trace) => {
    return prediction.answer && prediction.reasoning ? 1 : 0;
  },
});

const optimized = await teleprompter.compile({
  student: program,
  trainset,
});

// Use optimized program
const result = await optimized.forward({
  question: 'What is TypeScript?',
});

console.log(result.answer); // Optimized answer
console.log(result.reasoning); // Optimized reasoning
```

### Advanced MIPROv2 Usage

```typescript
const mipro = new MIPROv2({
  metric: customMetric,
  auto: 'heavy', // light, medium, heavy
  max_bootstrapped_demos: 4,
  max_labeled_demos: 4,
  verbose: true,
  track_stats: true,
});

const optimized = await mipro.compile({
  student: program,
  trainset,
  valset,
  teacher: teacherProgram,
  minibatch: true,
  minibatch_size: 50,
  program_aware_proposer: true, // Use program structure
  data_aware_proposer: true, // Use training data insights
  tip_aware_proposer: true, // Include prompting tips
  fewshot_aware_proposer: true, // Consider few-shot context
});

// Access optimization statistics
console.log(optimized.score); // Final optimization score
console.log(optimized.total_calls); // LLM calls made
console.log(optimized.trial_logs); // Detailed optimization logs
```

### Ensemble Optimization

```typescript
const ensemble = new Ensemble({
  reduce_fn: (predictions) => {
    // Custom prediction combination logic
    const answers = predictions.map((p) => p.answer);
    const mostCommon = getMostFrequent(answers);
    return {
      answer: mostCommon,
      confidence: getConfidence(predictions),
    };
  },
});

const optimized = await ensemble.compile({
  student: program,
  trainset,
});
```

## ğŸ—ï¸ Architecture

### Teleprompter Hierarchy

```
Teleprompter (Abstract Base)
â”œâ”€â”€ LabeledFewShot (Simple k-shot)
â”œâ”€â”€ BootstrapFewShot (Teacher/student bootstrapping)
â”œâ”€â”€ MIPROv2 (Advanced multi-objective optimization)
â””â”€â”€ Ensemble (Multi-model combination)
```

### Program Structure

```
Module (DSPy Program)
â”œâ”€â”€ Predictors[] (Individual prediction units)
â”‚   â”œâ”€â”€ Signature (Input/output specification)
â”‚   â”œâ”€â”€ Demos[] (Few-shot examples)
â”‚   â””â”€â”€ Config (Model parameters)
â””â”€â”€ forward() (Execution method)
```

### Optimization Workflow

1. **Signature Definition** - Define inputs, outputs, and instructions
2. **Program Creation** - Build predictors with signatures
3. **Training Data** - Provide examples for optimization
4. **Teleprompter Selection** - Choose optimization algorithm
5. **Compilation** - Run optimization process
6. **Deployment** - Use optimized program in production

## ğŸ”§ Configuration

### @zen-ai/shared Integration

```typescript
import { initializeDSPyService } from '../lib/dspy';

// Initialize with shared services
await initializeDSPyService();

// DSPy will automatically use:
// - SharedLLMService for model calls
// - SharedLogger for structured logging
// - SharedStorage for KV persistence
// - SharedConfig for centralized configuration
```

### Standalone Mode

```typescript
// DSPy works standalone with fallback implementations
// No additional configuration required
```

## ğŸ“Š Performance & Metrics

### Optimization Metrics

- **Score Tracking** - Optimization score progression
- **LLM Call Counting** - Cost and usage monitoring
- **Minibatch Efficiency** - Evaluation optimization
- **Success Rate** - Task completion metrics

### Monitoring

```typescript
// Enable detailed tracking
const teleprompter = new MIPROv2({
  track_stats: true,
  verbose: true,
  log_dir: './optimization_logs',
});

// Access metrics after optimization
const metrics = {
  score: optimized.score,
  totalCalls: optimized.total_calls,
  promptModelCalls: optimized.prompt_model_total_calls,
  candidatePrograms: optimized.candidate_programs,
  trialLogs: optimized.trial_logs,
};
```

## ğŸ§ª Testing

Run the comprehensive example:

```bash
npx ts-node src/examples/dspy-stanford-example.ts
```

### Custom Metrics

```typescript
const customMetric = (example, prediction, trace) => {
  // Exact match scoring
  if (prediction.answer === example.expected_answer) {
    return 1.0;
  }

  // Partial credit for semantic similarity
  const similarity = calculateSimilarity(
    prediction.answer,
    example.expected_answer
  );
  return similarity > 0.8 ? 0.5 : 0;
};

const teleprompter = new BootstrapFewShot({
  metric: customMetric,
  metric_threshold: 0.8,
});
```

## ğŸš€ Production Deployment

### Best Practices

1. **Use MIPROv2** for sophisticated optimization
2. **Set appropriate auto mode** (light/medium/heavy)
3. **Enable @zen-ai/shared** for production features
4. **Monitor LLM usage** for cost control
5. **Cache optimized programs** for reuse
6. **Validate metrics** against business objectives

### Scaling Considerations

- **Minibatch evaluation** for large datasets
- **Parallel optimization** with multiple workers
- **Progressive optimization** with staged rollouts
- **A/B testing** with multiple teleprompters

## ğŸ“š Comparison with Stanford DSPy

| Feature              | Stanford DSPy (Python) | This Implementation           |
| -------------------- | ---------------------- | ----------------------------- |
| LabeledFewShot       | âœ…                     | âœ… Full compatibility         |
| BootstrapFewShot     | âœ…                     | âœ… Complete algorithm         |
| MIPROv2              | âœ…                     | âœ… All features ported        |
| Ensemble             | âœ…                     | âœ… Custom reduction functions |
| Type Safety          | âŒ                     | âœ… Full TypeScript            |
| @zen-ai Integration  | âŒ                     | âœ… Production ready           |
| Standalone Operation | âŒ                     | âœ… Graceful fallbacks         |

## ğŸ¤ Contributing

This is part of the claude-code-zen project. The DSPy implementation is feature-complete and production-ready.

## ğŸ“„ License

MIT License - see claude-code-zen project license.

## ğŸ™ Acknowledgments

- Stanford NLP Group for the original DSPy framework
- @zen-ai/shared for infrastructure integration
- Claude Code Zen team for TypeScript implementation

---

**Built with â¤ï¸ for the TypeScript community**

_"Bringing Stanford's sophisticated prompt optimization to TypeScript with production-grade reliability."_
