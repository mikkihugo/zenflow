#!/usr/bin/env node

/**
 * Test updated GitHub Copilot configuration with all available models
 */

const fs = require('fs');
const path = require('path');
const { homedir } = require('os');

async function testUpdatedConfig() {
  console.log('üöÄ Testing Updated GitHub Copilot Configuration');
  console.log('==============================================\n');

  try {
    // Load configuration
    const { getProvider } = require('./packages/implementation-packages/llm-routing/dist/config/providers.js');
    const copilotConfig = getProvider('copilot');
    
    console.log('üìã Updated Configuration:');
    console.log(`   Display Name: ${copilotConfig.displayName}`);
    console.log(`   Default Model: ${copilotConfig.defaultModel}`);
    console.log(`   Available Models: ${copilotConfig.models.length}`);
    console.log(`   Models: ${copilotConfig.models.join(', ')}`);

    // Load token
    const tokenPath = copilotConfig.api?.tokenPath?.replace('~', homedir());
    const tokenData = JSON.parse(fs.readFileSync(tokenPath, 'utf8'));
    const token = tokenData.access_token;

    // Test key models
    console.log('\nüß™ Testing Key Models:');
    console.log('=====================');

    const testModels = ['gpt-5', 'o3', 'o3-mini', 'o4-mini', 'claude-opus-4', 'gpt-4o'];
    
    for (const modelId of testModels) {
      if (copilotConfig.models.includes(modelId)) {
        try {
          console.log(`\nüîç Testing ${modelId}...`);
          
          const chatResponse = await fetch('https://api.githubcopilot.com/chat/completions', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${token}`,
              'Content-Type': 'application/json',
              'User-Agent': 'claude-code-zen/1.0',
              'Copilot-Integration-Id': 'vscode-chat'
            },
            body: JSON.stringify({
              model: modelId,
              messages: [
                {
                  role: 'user',
                  content: `Hello from ${modelId}! Respond with your model name and a brief capability summary.`
                }
              ],
              max_tokens: 100,
              temperature: 0.3
            })
          });

          if (chatResponse.ok) {
            const result = await chatResponse.json();
            const response = result.choices?.[0]?.message?.content || 'No response';
            const actualModel = result.model || modelId;
            const usage = result.usage || {};
            
            console.log(`‚úÖ ${modelId}: Working`);
            console.log(`   Actual Model: ${actualModel}`);
            console.log(`   Response: ${response.substring(0, 150)}${response.length > 150 ? '...' : ''}`);
            console.log(`   Tokens: ${usage.total_tokens || 'unknown'} (${usage.prompt_tokens}‚Üí${usage.completion_tokens})`);
          } else {
            const errorText = await chatResponse.text();
            console.log(`‚ùå ${modelId}: Failed (${chatResponse.status})`);
            console.log(`   Error: ${errorText.substring(0, 100)}...`);
          }
        } catch (error) {
          console.log(`‚ùå ${modelId}: Error (${error.message})`);
        }
        
        // Small delay between requests
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }

    console.log('\nüìä Configuration Summary:');
    console.log('========================');
    console.log(`‚úÖ Total models available: ${copilotConfig.models.length}`);
    console.log(`‚úÖ Default model: ${copilotConfig.defaultModel}`);
    console.log(`‚úÖ Priority: ${copilotConfig.routing.priority} (highest)`);
    console.log(`‚úÖ Context window: ${copilotConfig.maxContextTokens.toLocaleString()} tokens`);
    console.log(`‚úÖ Output limit: ${copilotConfig.maxOutputTokens.toLocaleString()} tokens`);
    console.log(`‚úÖ API endpoint: ${copilotConfig.api.baseUrl}`);
    
    console.log('\nüéØ Advanced Models Available:');
    console.log('============================');
    console.log('‚Ä¢ GPT-5: Latest OpenAI model');
    console.log('‚Ä¢ O3/O3-mini: OpenAI reasoning models');
    console.log('‚Ä¢ O4-mini: Latest OpenAI compact model');
    console.log('‚Ä¢ Claude Opus 4: Anthropic\'s latest');
    console.log('‚Ä¢ Claude Sonnet 4: Anthropic\'s balanced model');
    console.log('‚Ä¢ Gemini 2.5 Pro: Google\'s latest');
    
    console.log('\nüöÄ Integration Status: READY');
    console.log('GitHub Copilot with comprehensive model support is configured and working!');

  } catch (error) {
    console.error('\n‚ùå Test failed:', error.message);
    process.exit(1);
  }
}

testUpdatedConfig();